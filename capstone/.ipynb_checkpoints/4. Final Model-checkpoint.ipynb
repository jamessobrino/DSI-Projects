{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, GRU, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/player_game_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GAME_DATE_EST'] = pd.to_datetime(df['GAME_DATE_EST'])\n",
    "df = df.set_index('GAME_DATE_EST')\n",
    "df.dropna(inplace= True)\n",
    "df.sort_index(inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PLAYER_NAME</th>\n",
       "      <th>PLAYER_ID</th>\n",
       "      <th>GAME_ID</th>\n",
       "      <th>SEASON</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG_PCT</th>\n",
       "      <th>FG3M</th>\n",
       "      <th>FG3A</th>\n",
       "      <th>FG3_PCT</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT_PCT</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TNO</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "      <th>PLUS_MINUS</th>\n",
       "      <th>SECONDS</th>\n",
       "      <th>FTSY_PTS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAME_DATE_EST</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-10-02</th>\n",
       "      <td>C.J. Wilcox</td>\n",
       "      <td>203912</td>\n",
       "      <td>11500001</td>\n",
       "      <td>2015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>446</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-02</th>\n",
       "      <td>Jameer Nelson</td>\n",
       "      <td>2749</td>\n",
       "      <td>11500001</td>\n",
       "      <td>2015</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1141</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-02</th>\n",
       "      <td>Randy Foye</td>\n",
       "      <td>200751</td>\n",
       "      <td>11500001</td>\n",
       "      <td>2015</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>1138</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-02</th>\n",
       "      <td>Wilson Chandler</td>\n",
       "      <td>201163</td>\n",
       "      <td>11500001</td>\n",
       "      <td>2015</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.417</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>1382</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-02</th>\n",
       "      <td>JJ Hickson</td>\n",
       "      <td>201581</td>\n",
       "      <td>11500001</td>\n",
       "      <td>2015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>1148</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   PLAYER_NAME  PLAYER_ID   GAME_ID  SEASON  FGM   FGA  \\\n",
       "GAME_DATE_EST                                                            \n",
       "2015-10-02         C.J. Wilcox     203912  11500001    2015  1.0   2.0   \n",
       "2015-10-02       Jameer Nelson       2749  11500001    2015  3.0   8.0   \n",
       "2015-10-02          Randy Foye     200751  11500001    2015  2.0   4.0   \n",
       "2015-10-02     Wilson Chandler     201163  11500001    2015  5.0  12.0   \n",
       "2015-10-02          JJ Hickson     201581  11500001    2015  1.0   7.0   \n",
       "\n",
       "               FG_PCT  FG3M  FG3A  FG3_PCT  FTM  FTA  FT_PCT  OREB  DREB  REB  \\\n",
       "GAME_DATE_EST                                                                   \n",
       "2015-10-02      0.500   1.0   2.0    0.500  0.0  0.0    0.00   0.0   0.0  0.0   \n",
       "2015-10-02      0.375   1.0   3.0    0.333  3.0  4.0    0.75   0.0   3.0  3.0   \n",
       "2015-10-02      0.500   2.0   2.0    1.000  0.0  0.0    0.00   0.0   0.0  0.0   \n",
       "2015-10-02      0.417   1.0   3.0    0.333  0.0  1.0    0.00   1.0   7.0  8.0   \n",
       "2015-10-02      0.143   0.0   0.0    0.000  0.0  0.0    0.00   1.0   5.0  6.0   \n",
       "\n",
       "               AST  STL  BLK  TNO   PF   PTS  PLUS_MINUS  SECONDS  FTSY_PTS  \n",
       "GAME_DATE_EST                                                                \n",
       "2015-10-02     0.0  0.0  0.0  0.0  0.0   3.0         0.0      446       2.0  \n",
       "2015-10-02     7.0  0.0  0.0  1.0  3.0  10.0         8.0     1141      16.5  \n",
       "2015-10-02     0.0  0.0  0.0  1.0  3.0   6.0       -16.0     1138       3.0  \n",
       "2015-10-02     2.0  2.0  0.0  0.0  1.0  11.0        -8.0     1382      18.0  \n",
       "2015-10-02     0.0  0.0  0.0  3.0  2.0   2.0       -14.0     1148      -1.0  "
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= df[['PLAYER_NAME', 'PLAYER_ID','GAME_ID', 'SEASON','FGM','FGA','FG_PCT','FG3M','FG3A','FG3_PCT','FTM','FTA','FT_PCT','OREB','DREB','REB','AST','STL','BLK','TNO','PF','PTS','PLUS_MINUS','SECONDS','FTSY_PTS']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#issue with time series generator on y_test? It is a single value which is causing an error, Cannot wrap y_test in a list raises error\n",
    "#start_index+length=1 > end_index=0` is disallowed, as no part of the sequence would be left to be used as current step.\n",
    "# above error prevents manually setting stop and start index with y_test len of 1\n",
    "# \n",
    "def player_output():\n",
    "#     day = input('What day would you like to predict? Format: YYYY-MM-DD')\n",
    "#     player = input('What player would you like to predict?')\n",
    "    \n",
    "    day= '2016-11-25'\n",
    "    player= 'Stephen Curry'\n",
    "    \n",
    "    data_df = df.loc[df['PLAYER_NAME'] == player]\n",
    "    data_df = data_df.iloc[:,4:-1].rolling(window=5).mean()\n",
    "    data_df['FTSY_PTS'] = df.loc[df['PLAYER_NAME']== player]['FTSY_PTS']\n",
    "    data_df.dropna(inplace= True)\n",
    "    \n",
    "    \n",
    "    X_train = data_df.loc['2015-10-02': day].drop(columns= 'FTSY_PTS')\n",
    "    \n",
    "    y_train = data_df.loc['2015-10-02': day]['FTSY_PTS']\n",
    "    \n",
    "    \n",
    "    X_test = data_df.loc[day].drop('FTSY_PTS')\n",
    "    y_test = [data_df.loc[day]['FTSY_PTS']]\n",
    "\n",
    "    ss = StandardScaler()\n",
    "    X_train_sc = ss.fit_transform(X_train)\n",
    "    X_test_sc = ss.transform(X_test.values.reshape(1,-1))\n",
    "    \n",
    "#     train_seq = TimeseriesGenerator(X_train_sc, y_train, length=1, batch_size=64)\n",
    "#     test_seq = TimeseriesGenerator(X_test_sc, y_test, length = 1, batch_size=64)\n",
    "    \n",
    "#     model = Sequential()\n",
    "\n",
    "#     model.add(LSTM(64, input_shape=(1,20), return_sequences=True))\n",
    "#     model.add(LSTM(16, return_sequences=False))\n",
    "\n",
    "#     model.add(Dense(16, activation= 'relu'))\n",
    "#     model.add(Dropout(.1))\n",
    "\n",
    "#     model.add(Dense(8, activation= 'relu'))\n",
    "#     model.add(Dropout(.1))\n",
    "\n",
    "#     model.add(Dense(1))\n",
    "#     model.compile(optimizer='adam', loss= 'mse', metrics= ['mae'])\n",
    "\n",
    "#     early_stop = EarlyStopping(patience = 5)\n",
    "\n",
    "#     history=model.fit(train_seq, epochs=100, validation_data= test_seq, verbose=1, callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def player_output():\n",
    "    day = input('What day would you like to predict? Format: YYYY-MM-DD')\n",
    "    player = input('What player would you like to predict?')\n",
    "    \n",
    "    data_df = df.loc[df['PLAYER_NAME'] == player]\n",
    "    data_df = data_df.iloc[:,4:-1].rolling(window=5).mean()\n",
    "    data_df['FTSY_PTS'] = df.loc[df['PLAYER_NAME']== player]['FTSY_PTS']\n",
    "    data_df.dropna(inplace= True)\n",
    "    \n",
    "    \n",
    "    X_train = data_df.loc['2015-10-02': day].drop(columns= 'FTSY_PTS')\n",
    "    y_train = data_df.loc['2015-10-02': day]['FTSY_PTS']\n",
    "    \n",
    "    #https://stackoverflow.com/questions/46533410/pandas-datetimeindex-shifting-over-index\n",
    "    day_ind = data_df.index.get_loc(day)\n",
    "    X_test = data_df.iloc[[day_ind,day_ind+1]].drop(columns = 'FTSY_PTS')\n",
    "    y_test = data_df.iloc[[day_ind,day_ind+1]]['FTSY_PTS']\n",
    "\n",
    "    ss = StandardScaler()\n",
    "    X_train_sc = ss.fit_transform(X_train)\n",
    "    X_test_sc = ss.transform(X_test)\n",
    "    \n",
    "    train_seq = TimeseriesGenerator(X_train_sc, y_train, length=1, batch_size=64)\n",
    "    #test_seq = TimeseriesGenerator(X_test_sc, y_test, length = 1, batch_size=64)\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(64, input_shape=(1,20), return_sequences=True))\n",
    "    model.add(LSTM(32, return_sequences=False))\n",
    "\n",
    "    model.add(Dense(32, activation= 'relu'))\n",
    "    model.add(Dropout(.1))\n",
    "\n",
    "    model.add(Dense(8, activation= 'relu'))\n",
    "    model.add(Dropout(.1))\n",
    "\n",
    "    model.add(Dense(2))\n",
    "    model.compile(optimizer='adam', loss= 'mse', metrics= ['mae'])\n",
    "\n",
    "    early_stop = EarlyStopping(patience = 5, restore_best_weights=True)\n",
    "\n",
    "    history=model.fit(train_seq, epochs=100, validation_data= test_seq,\n",
    "                      verbose=1, callbacks = [early_stop])\n",
    "    output = model.predict(test_seq)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "What day would you like to predict? Format: YYYY-MM-DD 2016-11-25\n",
      "What player would you like to predict? Stephen Curry\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 3s 645ms/step - loss: 1251.2069 - mae: 33.5591 - val_loss: 1680.4666 - val_mae: 40.9935\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1250.5638 - mae: 33.5492 - val_loss: 1680.0211 - val_mae: 40.9881\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1249.8774 - mae: 33.5394 - val_loss: 1679.5725 - val_mae: 40.9826\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1249.2634 - mae: 33.5306 - val_loss: 1679.1080 - val_mae: 40.9769\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1248.6212 - mae: 33.5208 - val_loss: 1678.6296 - val_mae: 40.9711\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1247.8979 - mae: 33.5105 - val_loss: 1678.1257 - val_mae: 40.9649\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1247.3134 - mae: 33.5010 - val_loss: 1677.5525 - val_mae: 40.9579\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1246.5986 - mae: 33.4907 - val_loss: 1676.8884 - val_mae: 40.9498\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1245.6443 - mae: 33.4771 - val_loss: 1676.2351 - val_mae: 40.9418\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1244.9449 - mae: 33.4663 - val_loss: 1675.5776 - val_mae: 40.9338\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1243.7009 - mae: 33.4473 - val_loss: 1674.8992 - val_mae: 40.9255\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1242.3530 - mae: 33.4278 - val_loss: 1674.1021 - val_mae: 40.9158\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1241.0868 - mae: 33.4087 - val_loss: 1673.1699 - val_mae: 40.9044\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1239.6810 - mae: 33.3901 - val_loss: 1672.1332 - val_mae: 40.8917\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1238.8115 - mae: 33.3755 - val_loss: 1671.0707 - val_mae: 40.8787\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1237.2788 - mae: 33.3516 - val_loss: 1669.9099 - val_mae: 40.8645\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1235.0868 - mae: 33.3194 - val_loss: 1668.6482 - val_mae: 40.8491\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1233.0841 - mae: 33.2906 - val_loss: 1667.2866 - val_mae: 40.8324\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1231.5981 - mae: 33.2685 - val_loss: 1665.7229 - val_mae: 40.8132\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1228.6949 - mae: 33.2287 - val_loss: 1664.0082 - val_mae: 40.7922\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1225.8450 - mae: 33.1873 - val_loss: 1662.1152 - val_mae: 40.7690\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1223.3710 - mae: 33.1470 - val_loss: 1659.9961 - val_mae: 40.7430\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1218.7883 - mae: 33.0741 - val_loss: 1657.7705 - val_mae: 40.7157\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1214.9032 - mae: 33.0219 - val_loss: 1655.1404 - val_mae: 40.6833\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1210.5001 - mae: 32.9602 - val_loss: 1652.1682 - val_mae: 40.6468\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1205.5549 - mae: 32.8873 - val_loss: 1648.8534 - val_mae: 40.6060\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1200.0790 - mae: 32.7987 - val_loss: 1645.2848 - val_mae: 40.5620\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1194.6169 - mae: 32.7159 - val_loss: 1640.9594 - val_mae: 40.5086\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1182.7401 - mae: 32.5506 - val_loss: 1636.0109 - val_mae: 40.4474\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1179.1555 - mae: 32.4641 - val_loss: 1630.6221 - val_mae: 40.3807\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1164.2098 - mae: 32.2657 - val_loss: 1624.0282 - val_mae: 40.2989\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1162.2520 - mae: 32.2053 - val_loss: 1616.7800 - val_mae: 40.2088\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 1144.4204 - mae: 31.9577 - val_loss: 1608.2734 - val_mae: 40.1028\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1135.2750 - mae: 31.7905 - val_loss: 1597.9561 - val_mae: 39.9738\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1121.2759 - mae: 31.5877 - val_loss: 1586.0474 - val_mae: 39.8244\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1109.3127 - mae: 31.4029 - val_loss: 1572.3296 - val_mae: 39.6516\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1084.4899 - mae: 30.9970 - val_loss: 1557.2903 - val_mae: 39.4612\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1072.2367 - mae: 30.7697 - val_loss: 1539.9965 - val_mae: 39.2411\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1058.5890 - mae: 30.4834 - val_loss: 1520.2878 - val_mae: 38.9888\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1036.8496 - mae: 30.1569 - val_loss: 1497.4531 - val_mae: 38.6942\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1011.9767 - mae: 29.7197 - val_loss: 1471.3342 - val_mae: 38.3544\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 983.5712 - mae: 29.2630 - val_loss: 1441.9277 - val_mae: 37.9681\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 952.3704 - mae: 28.7829 - val_loss: 1407.8447 - val_mae: 37.5152\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 920.7207 - mae: 28.1324 - val_loss: 1371.7930 - val_mae: 37.0299\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 885.2531 - mae: 27.4585 - val_loss: 1332.1353 - val_mae: 36.4883\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 866.1030 - mae: 27.1724 - val_loss: 1287.5261 - val_mae: 35.8691\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 832.2179 - mae: 26.5216 - val_loss: 1240.5162 - val_mae: 35.2044\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 788.5397 - mae: 25.7099 - val_loss: 1189.3171 - val_mae: 34.4654\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 767.1611 - mae: 25.0413 - val_loss: 1134.9211 - val_mae: 33.6620\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 710.4024 - mae: 24.1190 - val_loss: 1075.5520 - val_mae: 32.7619\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 706.3504 - mae: 23.7504 - val_loss: 1015.3845 - val_mae: 31.8229\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 645.3088 - mae: 22.4075 - val_loss: 951.4218 - val_mae: 30.7922\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 614.8201 - mae: 21.9807 - val_loss: 887.9841 - val_mae: 29.7336\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 573.0654 - mae: 20.8847 - val_loss: 822.1389 - val_mae: 28.5920\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 534.7241 - mae: 19.9493 - val_loss: 756.7825 - val_mae: 27.4105\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 521.7631 - mae: 19.2833 - val_loss: 691.5672 - val_mae: 26.1768\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 445.3678 - mae: 17.8182 - val_loss: 626.6846 - val_mae: 24.8869\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 433.7929 - mae: 17.1734 - val_loss: 564.7529 - val_mae: 23.5880\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 425.4222 - mae: 17.1589 - val_loss: 505.6747 - val_mae: 22.2767\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 380.1948 - mae: 16.0285 - val_loss: 449.8588 - val_mae: 20.9604\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 380.5149 - mae: 15.8166 - val_loss: 397.9950 - val_mae: 19.6564\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 307.8776 - mae: 14.0888 - val_loss: 350.0339 - val_mae: 18.3668\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 308.6309 - mae: 14.2516 - val_loss: 306.3100 - val_mae: 17.1056\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 245.9689 - mae: 12.6008 - val_loss: 267.5120 - val_mae: 15.9032\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 266.2124 - mae: 12.8930 - val_loss: 233.5199 - val_mae: 14.7705\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 247.8866 - mae: 12.7818 - val_loss: 202.9325 - val_mae: 13.6725\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 251.9587 - mae: 12.4513 - val_loss: 177.6950 - val_mae: 12.7006\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 226.9590 - mae: 11.9956 - val_loss: 156.8204 - val_mae: 11.8434\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 218.3730 - mae: 11.7662 - val_loss: 139.5977 - val_mae: 11.0954\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 249.0366 - mae: 12.7706 - val_loss: 125.7502 - val_mae: 10.4668\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 236.3772 - mae: 12.3978 - val_loss: 115.6080 - val_mae: 9.9975\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 236.4330 - mae: 12.2313 - val_loss: 107.0864 - val_mae: 9.5955\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 202.6437 - mae: 11.1480 - val_loss: 100.0048 - val_mae: 9.2594\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 233.5063 - mae: 11.9720 - val_loss: 95.6764 - val_mae: 9.0720\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 211.3236 - mae: 11.7346 - val_loss: 93.1830 - val_mae: 8.9887\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 190.4677 - mae: 11.2868 - val_loss: 91.4055 - val_mae: 8.9450\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 199.8878 - mae: 11.5406 - val_loss: 92.1202 - val_mae: 9.0424\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 182.4406 - mae: 11.0086 - val_loss: 93.1454 - val_mae: 9.1523\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 209.3835 - mae: 11.5851 - val_loss: 95.0210 - val_mae: 9.3041\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 210.8412 - mae: 11.7622 - val_loss: 95.9444 - val_mae: 9.3964\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 197.8023 - mae: 11.4201 - val_loss: 96.5783 - val_mae: 9.4685\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[35.43041 , 28.679668]], dtype=float32)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 4s 669ms/step - loss: 1254.3416 - mae: 33.5913 - val_loss: 1680.8000 - val_mae: 40.9976\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1253.7880 - mae: 33.5826 - val_loss: 1680.3232 - val_mae: 40.9917\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1253.2491 - mae: 33.5746 - val_loss: 1679.8733 - val_mae: 40.9863\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1252.8134 - mae: 33.5685 - val_loss: 1679.3655 - val_mae: 40.9801\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1252.4003 - mae: 33.5620 - val_loss: 1678.8080 - val_mae: 40.9733\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1251.9908 - mae: 33.5559 - val_loss: 1678.2061 - val_mae: 40.9659\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1251.6517 - mae: 33.5508 - val_loss: 1677.5718 - val_mae: 40.9582\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1251.0593 - mae: 33.5426 - val_loss: 1676.8978 - val_mae: 40.9499\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1250.6648 - mae: 33.5364 - val_loss: 1676.1782 - val_mae: 40.9412\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1250.0312 - mae: 33.5269 - val_loss: 1675.4348 - val_mae: 40.9321\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1249.4594 - mae: 33.5183 - val_loss: 1674.6422 - val_mae: 40.9224\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1248.8821 - mae: 33.5103 - val_loss: 1673.7789 - val_mae: 40.9118\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1248.2521 - mae: 33.5005 - val_loss: 1672.8470 - val_mae: 40.9004\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1247.7463 - mae: 33.4922 - val_loss: 1671.8464 - val_mae: 40.8882\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1246.6409 - mae: 33.4763 - val_loss: 1670.7488 - val_mae: 40.8748\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1246.0013 - mae: 33.4656 - val_loss: 1669.5734 - val_mae: 40.8604\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1244.9508 - mae: 33.4513 - val_loss: 1668.2601 - val_mae: 40.8443\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1244.1008 - mae: 33.4389 - val_loss: 1666.8120 - val_mae: 40.8266\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1242.3989 - mae: 33.4130 - val_loss: 1665.1688 - val_mae: 40.8064\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1241.5226 - mae: 33.3986 - val_loss: 1663.3545 - val_mae: 40.7842\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1239.5826 - mae: 33.3706 - val_loss: 1661.2395 - val_mae: 40.7583\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 1238.8578 - mae: 33.3605 - val_loss: 1658.7671 - val_mae: 40.7279\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1236.2258 - mae: 33.3222 - val_loss: 1655.9817 - val_mae: 40.6937\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1234.5135 - mae: 33.2968 - val_loss: 1652.7021 - val_mae: 40.6533\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1231.3851 - mae: 33.2495 - val_loss: 1648.8838 - val_mae: 40.6063\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1229.1478 - mae: 33.2205 - val_loss: 1644.4585 - val_mae: 40.5517\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1226.3672 - mae: 33.1730 - val_loss: 1639.2805 - val_mae: 40.4878\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1222.9766 - mae: 33.1225 - val_loss: 1633.3528 - val_mae: 40.4144\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1218.6620 - mae: 33.0580 - val_loss: 1626.2209 - val_mae: 40.3260\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1215.1426 - mae: 33.0006 - val_loss: 1618.1096 - val_mae: 40.2251\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1211.6013 - mae: 32.9532 - val_loss: 1608.6643 - val_mae: 40.1073\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1203.3066 - mae: 32.8390 - val_loss: 1597.6440 - val_mae: 39.9695\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1199.8237 - mae: 32.7729 - val_loss: 1585.1650 - val_mae: 39.8127\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1190.9928 - mae: 32.6323 - val_loss: 1570.4958 - val_mae: 39.6276\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1181.1409 - mae: 32.4871 - val_loss: 1553.2998 - val_mae: 39.4092\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1172.8320 - mae: 32.3383 - val_loss: 1533.6392 - val_mae: 39.1579\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1160.8021 - mae: 32.1497 - val_loss: 1511.5857 - val_mae: 38.8739\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1148.0770 - mae: 31.9776 - val_loss: 1486.2610 - val_mae: 38.5448\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1135.6326 - mae: 31.7719 - val_loss: 1458.0894 - val_mae: 38.1750\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1121.9308 - mae: 31.5484 - val_loss: 1427.4491 - val_mae: 37.7683\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1105.9117 - mae: 31.2536 - val_loss: 1393.3164 - val_mae: 37.3097\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1086.5656 - mae: 30.9404 - val_loss: 1355.8579 - val_mae: 36.7992\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1064.8995 - mae: 30.5988 - val_loss: 1314.5751 - val_mae: 36.2276\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1054.6987 - mae: 30.3982 - val_loss: 1271.1963 - val_mae: 35.6162\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1026.3577 - mae: 29.9408 - val_loss: 1224.4781 - val_mae: 34.9447\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 989.0981 - mae: 29.3061 - val_loss: 1175.0625 - val_mae: 34.2181\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 969.7184 - mae: 28.8728 - val_loss: 1122.2505 - val_mae: 33.4224\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 942.0629 - mae: 28.3637 - val_loss: 1068.3622 - val_mae: 32.5878\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 893.9469 - mae: 27.6045 - val_loss: 1012.1312 - val_mae: 31.6845\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 866.6188 - mae: 26.8927 - val_loss: 954.3326 - val_mae: 30.7236\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 828.0067 - mae: 26.3076 - val_loss: 894.1357 - val_mae: 29.6830\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 805.0475 - mae: 25.7581 - val_loss: 833.9106 - val_mae: 28.5968\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 754.9421 - mae: 24.7925 - val_loss: 773.4799 - val_mae: 27.4590\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 708.0756 - mae: 23.8072 - val_loss: 712.8013 - val_mae: 26.2666\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 681.6435 - mae: 23.0832 - val_loss: 652.5533 - val_mae: 25.0290\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 636.8596 - mae: 22.2201 - val_loss: 593.5310 - val_mae: 23.7594\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 602.0760 - mae: 21.3696 - val_loss: 536.1616 - val_mae: 22.4650\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 555.7051 - mae: 20.2708 - val_loss: 480.5086 - val_mae: 21.1512\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 524.4863 - mae: 19.5757 - val_loss: 426.6541 - val_mae: 19.8129\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 458.5028 - mae: 18.1450 - val_loss: 375.4208 - val_mae: 18.4759\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 438.6759 - mae: 17.5603 - val_loss: 327.3370 - val_mae: 17.1568\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 401.2179 - mae: 16.4790 - val_loss: 282.6836 - val_mae: 15.8748\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 347.8731 - mae: 15.3875 - val_loss: 241.5618 - val_mae: 14.6167\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 364.4067 - mae: 15.5226 - val_loss: 204.7067 - val_mae: 13.3471\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 311.4018 - mae: 14.6331 - val_loss: 171.5575 - val_mae: 12.1191\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 299.0735 - mae: 13.9196 - val_loss: 142.4565 - val_mae: 10.9590\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 267.6001 - mae: 13.3350 - val_loss: 117.4436 - val_mae: 9.8861\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 271.9391 - mae: 12.8983 - val_loss: 96.4514 - val_mae: 8.9265\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 213.1513 - mae: 11.6553 - val_loss: 78.6754 - val_mae: 8.0555\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 245.2963 - mae: 12.0533 - val_loss: 64.4387 - val_mae: 7.3246\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 229.6710 - mae: 12.2998 - val_loss: 53.0610 - val_mae: 6.7112\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 213.7431 - mae: 11.7211 - val_loss: 44.1184 - val_mae: 6.2016\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 216.6946 - mae: 11.7301 - val_loss: 37.7983 - val_mae: 5.8404\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 192.7139 - mae: 11.1553 - val_loss: 33.4174 - val_mae: 5.5888\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 246.1592 - mae: 12.3915 - val_loss: 30.0856 - val_mae: 5.3778\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 190.4372 - mae: 10.9772 - val_loss: 28.4431 - val_mae: 5.2878\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 187.2955 - mae: 10.9761 - val_loss: 27.4828 - val_mae: 5.2301\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 167.3234 - mae: 10.2566 - val_loss: 28.1008 - val_mae: 5.3008\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 219.9440 - mae: 11.6830 - val_loss: 29.2154 - val_mae: 5.4002\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 172.9892 - mae: 10.3952 - val_loss: 30.8080 - val_mae: 5.5301\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 166.4447 - mae: 10.3490 - val_loss: 32.0190 - val_mae: 5.6198\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 190.8303 - mae: 10.8458 - val_loss: 33.0179 - val_mae: 5.6926\n",
      "          player     Game_1     Game_2\n",
      "0  Stephen Curry  36.090134  34.524742\n"
     ]
    }
   ],
   "source": [
    "day= '2016-11-25'\n",
    "player= 'Stephen Curry'\n",
    "\n",
    "\n",
    "data_df = df.loc[df['PLAYER_NAME'] == player]\n",
    "data_df = data_df.iloc[:,4:-1].rolling(window=5).mean()\n",
    "data_df['FTSY_PTS'] = df.loc[df['PLAYER_NAME']== player]['FTSY_PTS']\n",
    "data_df.dropna(inplace= True)\n",
    "\n",
    "\n",
    "X_train = data_df.loc['2015-10-02': day].drop(columns= 'FTSY_PTS')\n",
    "X_train = X_train[:-1]\n",
    "y_train = data_df.loc['2015-10-02': day]['FTSY_PTS']\n",
    "y_train = y_train[:-1]\n",
    "\n",
    "#https://stackoverflow.com/questions/46533410/pandas-datetimeindex-shifting-over-index\n",
    "day_ind = data_df.index.get_loc(day)\n",
    "X_test = data_df.iloc[[day_ind,day_ind+1]].drop(columns = 'FTSY_PTS')\n",
    "y_test = data_df.iloc[[day_ind,day_ind+1]]['FTSY_PTS']\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train_sc = ss.fit_transform(X_train)\n",
    "X_test_sc = ss.transform(X_test)\n",
    "\n",
    "train_seq = TimeseriesGenerator(X_train_sc, y_train, length=1, batch_size=64)\n",
    "test_seq = TimeseriesGenerator(X_test_sc, y_test, length = 1, batch_size=64)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(64, input_shape=(1,20), return_sequences=True))\n",
    "model.add(LSTM(32, return_sequences=False))\n",
    "\n",
    "model.add(Dense(32, activation= 'relu'))\n",
    "model.add(Dropout(.1))\n",
    "\n",
    "model.add(Dense(8, activation= 'relu'))\n",
    "model.add(Dropout(.1))\n",
    "\n",
    "model.add(Dense(2))\n",
    "model.compile(optimizer='adam', loss= 'mse', metrics= ['mae'])\n",
    "\n",
    "early_stop = EarlyStopping(patience = 5)\n",
    "\n",
    "results=model.fit(train_seq, epochs=100, validation_data=test_seq,\n",
    "                  verbose=1, callbacks = [early_stop])\n",
    "\n",
    "output= model.predict(test_seq)\n",
    "\n",
    "player_df = pd.DataFrame(columns = ['player', 'Game_1', 'Game_2'])\n",
    "row = pd.Series([player, output[0][0], output[0][1]], index=['player', 'Game_1', 'Game_2'])\n",
    "player_df = player_df.append(row, ignore_index= True)\n",
    "print(player_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player</th>\n",
       "      <th>Game_1</th>\n",
       "      <th>Game_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stephen Curry</td>\n",
       "      <td>36.090134</td>\n",
       "      <td>34.524742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          player     Game_1     Game_2\n",
       "0  Stephen Curry  36.090134  34.524742"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(results.history['loss'], label = 'Training Loss')\n",
    "plt.plot(results.history['val_loss'], label = 'Testing Loss')\n",
    "plt.legend();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 4s 300ms/step - loss: 1186.4424 - mae: 32.7880 - val_loss: 1023.7269 - val_mae: 31.9957\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1185.6611 - mae: 32.7760 - val_loss: 1023.0283 - val_mae: 31.9848\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1185.0491 - mae: 32.7667 - val_loss: 1022.4020 - val_mae: 31.9750\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1184.4236 - mae: 32.7572 - val_loss: 1021.7523 - val_mae: 31.9649\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1183.6600 - mae: 32.7453 - val_loss: 1020.9706 - val_mae: 31.9526\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1182.8823 - mae: 32.7331 - val_loss: 1020.0448 - val_mae: 31.9381\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1181.9771 - mae: 32.7199 - val_loss: 1019.0226 - val_mae: 31.9221\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1180.6848 - mae: 32.6990 - val_loss: 1017.7526 - val_mae: 31.9022\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1179.5162 - mae: 32.6812 - val_loss: 1016.3643 - val_mae: 31.8804\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1177.6898 - mae: 32.6526 - val_loss: 1014.4579 - val_mae: 31.8505\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1176.1602 - mae: 32.6280 - val_loss: 1012.1877 - val_mae: 31.8148\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1173.1744 - mae: 32.5809 - val_loss: 1009.5542 - val_mae: 31.7734\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1170.1150 - mae: 32.5339 - val_loss: 1006.1255 - val_mae: 31.7193\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1165.8783 - mae: 32.4641 - val_loss: 1001.0302 - val_mae: 31.6388\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1161.5518 - mae: 32.3996 - val_loss: 995.0876 - val_mae: 31.5446\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1154.1543 - mae: 32.2696 - val_loss: 986.4268 - val_mae: 31.4067\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1146.0168 - mae: 32.1423 - val_loss: 975.4116 - val_mae: 31.2305\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1132.6398 - mae: 31.9304 - val_loss: 961.3536 - val_mae: 31.0041\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1119.7069 - mae: 31.7094 - val_loss: 942.7306 - val_mae: 30.7015\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1099.5210 - mae: 31.3601 - val_loss: 916.4877 - val_mae: 30.2698\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1078.8574 - mae: 31.0026 - val_loss: 882.9678 - val_mae: 29.7092\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1047.1553 - mae: 30.4623 - val_loss: 844.7435 - val_mae: 29.0566\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1003.2375 - mae: 29.6691 - val_loss: 790.5524 - val_mae: 28.1050\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 968.8537 - mae: 29.0527 - val_loss: 731.1876 - val_mae: 27.0238\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 918.0727 - mae: 28.0488 - val_loss: 657.3767 - val_mae: 25.6150\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 855.0475 - mae: 26.8501 - val_loss: 574.7573 - val_mae: 23.9391\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 790.0862 - mae: 25.5370 - val_loss: 488.1400 - val_mae: 22.0454\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 709.2882 - mae: 23.7927 - val_loss: 396.8320 - val_mae: 19.8536\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 629.3715 - mae: 22.1131 - val_loss: 306.3618 - val_mae: 17.4111\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 556.4841 - mae: 20.2836 - val_loss: 219.9043 - val_mae: 14.7030\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 485.1606 - mae: 18.7298 - val_loss: 144.0233 - val_mae: 11.8270\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 408.5277 - mae: 16.7640 - val_loss: 84.1182 - val_mae: 8.9320\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 350.1470 - mae: 14.9846 - val_loss: 39.8501 - val_mae: 5.9686\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 312.0527 - mae: 14.0618 - val_loss: 13.9368 - val_mae: 3.1834\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 301.6096 - mae: 13.9564 - val_loss: 3.6589 - val_mae: 1.7799\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 268.5865 - mae: 13.2780 - val_loss: 3.5695 - val_mae: 1.4919\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 248.6013 - mae: 12.4675 - val_loss: 6.1376 - val_mae: 2.2384\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 231.1755 - mae: 12.0828 - val_loss: 7.8423 - val_mae: 2.7216\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 253.8694 - mae: 12.6674 - val_loss: 7.9409 - val_mae: 2.7903\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 216.1869 - mae: 11.2934 - val_loss: 6.4927 - val_mae: 2.5410\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 215.3652 - mae: 11.7320 - val_loss: 4.6523 - val_mae: 2.1567\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 9s 349ms/step - loss: 1186.0591 - mae: 32.7888 - val_loss: 1085.9463 - val_mae: 32.9537\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1184.2800 - mae: 32.7613 - val_loss: 1083.5618 - val_mae: 32.9175\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1182.5120 - mae: 32.7342 - val_loss: 1081.0269 - val_mae: 32.8790\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1180.3741 - mae: 32.7015 - val_loss: 1078.1520 - val_mae: 32.8352\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1177.6322 - mae: 32.6605 - val_loss: 1074.7932 - val_mae: 32.7840\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1175.4213 - mae: 32.6271 - val_loss: 1070.7972 - val_mae: 32.7230\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1171.2468 - mae: 32.5628 - val_loss: 1066.0117 - val_mae: 32.6498\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1167.5179 - mae: 32.5046 - val_loss: 1060.2245 - val_mae: 32.5611\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1163.5153 - mae: 32.4461 - val_loss: 1053.4304 - val_mae: 32.4566\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1156.3177 - mae: 32.3355 - val_loss: 1045.9237 - val_mae: 32.3407\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1149.3112 - mae: 32.2346 - val_loss: 1036.1550 - val_mae: 32.1893\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1140.2560 - mae: 32.0944 - val_loss: 1024.0748 - val_mae: 32.0011\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1129.3365 - mae: 31.9271 - val_loss: 1009.0364 - val_mae: 31.7653\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1118.0248 - mae: 31.7397 - val_loss: 989.8994 - val_mae: 31.4626\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1100.6182 - mae: 31.4733 - val_loss: 968.1917 - val_mae: 31.1157\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1077.5388 - mae: 31.0991 - val_loss: 939.7733 - val_mae: 30.6555\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1052.3052 - mae: 30.7104 - val_loss: 904.4104 - val_mae: 30.0731\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1025.7097 - mae: 30.2402 - val_loss: 864.0575 - val_mae: 29.3944\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 992.3758 - mae: 29.6513 - val_loss: 816.3268 - val_mae: 28.5708\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 940.9227 - mae: 28.7649 - val_loss: 767.6706 - val_mae: 27.7059\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 900.5853 - mae: 28.0716 - val_loss: 707.6888 - val_mae: 26.6009\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 846.6151 - mae: 27.1110 - val_loss: 644.0689 - val_mae: 25.3762\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 800.3021 - mae: 26.0571 - val_loss: 566.8521 - val_mae: 23.8057\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 735.0700 - mae: 24.7723 - val_loss: 490.5200 - val_mae: 22.1442\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 680.2458 - mae: 23.7088 - val_loss: 408.5750 - val_mae: 20.2092\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 614.3876 - mae: 22.1754 - val_loss: 327.3836 - val_mae: 18.0890\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 546.1902 - mae: 20.6292 - val_loss: 253.9790 - val_mae: 15.9314\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 477.1657 - mae: 18.9666 - val_loss: 186.3435 - val_mae: 13.6449\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 433.8407 - mae: 17.6910 - val_loss: 123.6628 - val_mae: 11.1135\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 369.0727 - mae: 16.2056 - val_loss: 76.6491 - val_mae: 8.7472\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 323.2751 - mae: 14.7778 - val_loss: 41.6083 - val_mae: 6.4415\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 271.4411 - mae: 13.4994 - val_loss: 18.6527 - val_mae: 4.3078\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 269.2394 - mae: 13.1415 - val_loss: 5.6675 - val_mae: 2.3639\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 215.9320 - mae: 11.7173 - val_loss: 0.9970 - val_mae: 0.9654\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 209.7267 - mae: 11.8943 - val_loss: 0.0551 - val_mae: 0.2079\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 198.1166 - mae: 11.3047 - val_loss: 0.6428 - val_mae: 0.7861\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 183.7285 - mae: 10.8318 - val_loss: 0.5936 - val_mae: 0.7614\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 181.7546 - mae: 10.5982 - val_loss: 0.0623 - val_mae: 0.2368\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 169.0371 - mae: 10.4760 - val_loss: 0.1515 - val_mae: 0.3869\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 162.2897 - mae: 10.2185 - val_loss: 1.3713 - val_mae: 1.1706\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 6s 356ms/step - loss: 1186.5076 - mae: 32.8019 - val_loss: 195.8798 - val_mae: 13.9957\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1184.8528 - mae: 32.7777 - val_loss: 195.4263 - val_mae: 13.9795\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1183.5775 - mae: 32.7580 - val_loss: 194.9439 - val_mae: 13.9622\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1181.9553 - mae: 32.7335 - val_loss: 194.2589 - val_mae: 13.9377\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1180.1697 - mae: 32.7052 - val_loss: 193.4230 - val_mae: 13.9076\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1178.4059 - mae: 32.6798 - val_loss: 192.4819 - val_mae: 13.8737\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1176.3781 - mae: 32.6481 - val_loss: 191.4736 - val_mae: 13.8373\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1173.5115 - mae: 32.6034 - val_loss: 190.2001 - val_mae: 13.7911\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1170.3911 - mae: 32.5543 - val_loss: 188.7286 - val_mae: 13.7375\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1166.1138 - mae: 32.4910 - val_loss: 187.0341 - val_mae: 13.6754\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1162.0442 - mae: 32.4225 - val_loss: 184.5870 - val_mae: 13.5853\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1156.0087 - mae: 32.3346 - val_loss: 182.0560 - val_mae: 13.4913\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1148.0306 - mae: 32.2087 - val_loss: 178.8101 - val_mae: 13.3696\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1136.6676 - mae: 32.0352 - val_loss: 174.4444 - val_mae: 13.2039\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1123.1180 - mae: 31.8236 - val_loss: 169.1173 - val_mae: 12.9984\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1106.2761 - mae: 31.5516 - val_loss: 162.1261 - val_mae: 12.7228\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1089.1858 - mae: 31.2533 - val_loss: 154.2760 - val_mae: 12.4049\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1060.4458 - mae: 30.7766 - val_loss: 143.4786 - val_mae: 11.9514\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1024.8960 - mae: 30.1841 - val_loss: 131.9777 - val_mae: 11.4453\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 994.7729 - mae: 29.6455 - val_loss: 117.0448 - val_mae: 10.7460\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 937.1437 - mae: 28.6568 - val_loss: 99.9586 - val_mae: 9.8738\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 885.5342 - mae: 27.6932 - val_loss: 81.7996 - val_mae: 8.8346\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 821.0231 - mae: 26.3326 - val_loss: 62.8069 - val_mae: 7.5607\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 754.8763 - mae: 24.9762 - val_loss: 45.3568 - val_mae: 6.0947\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 678.3679 - mae: 23.1756 - val_loss: 30.6210 - val_mae: 4.3336\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 612.2058 - mae: 21.9032 - val_loss: 22.1980 - val_mae: 4.0479\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 535.4183 - mae: 20.0990 - val_loss: 22.2411 - val_mae: 4.7097\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 475.1504 - mae: 18.4728 - val_loss: 34.4939 - val_mae: 5.4380\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 407.9233 - mae: 16.9946 - val_loss: 59.7774 - val_mae: 6.1293\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 346.8408 - mae: 15.5201 - val_loss: 97.6297 - val_mae: 7.2046\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 332.6136 - mae: 15.0907 - val_loss: 142.9831 - val_mae: 9.5012\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 5s 295ms/step - loss: 1472.1478 - mae: 36.9459 - val_loss: 1559.9077 - val_mae: 39.4957\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1470.8683 - mae: 36.9283 - val_loss: 1559.2438 - val_mae: 39.4873\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1469.4924 - mae: 36.9098 - val_loss: 1558.3423 - val_mae: 39.4758\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1468.3309 - mae: 36.8941 - val_loss: 1557.2955 - val_mae: 39.4626\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1466.9362 - mae: 36.8753 - val_loss: 1556.1406 - val_mae: 39.4479\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1465.3193 - mae: 36.8539 - val_loss: 1554.8226 - val_mae: 39.4312\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1463.6008 - mae: 36.8308 - val_loss: 1553.3425 - val_mae: 39.4125\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1461.7424 - mae: 36.8033 - val_loss: 1551.6949 - val_mae: 39.3915\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1459.3114 - mae: 36.7727 - val_loss: 1549.6848 - val_mae: 39.3660\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1456.6138 - mae: 36.7400 - val_loss: 1547.5671 - val_mae: 39.3391\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1453.1622 - mae: 36.6914 - val_loss: 1545.1959 - val_mae: 39.3089\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1450.3241 - mae: 36.6524 - val_loss: 1542.4779 - val_mae: 39.2743\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1444.6510 - mae: 36.5788 - val_loss: 1539.5006 - val_mae: 39.2364\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1438.3983 - mae: 36.4938 - val_loss: 1535.6021 - val_mae: 39.1866\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1432.4978 - mae: 36.4146 - val_loss: 1530.7571 - val_mae: 39.1247\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1423.9952 - mae: 36.2942 - val_loss: 1525.0369 - val_mae: 39.0514\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1412.1060 - mae: 36.1270 - val_loss: 1517.3879 - val_mae: 38.9532\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1397.3750 - mae: 35.9417 - val_loss: 1508.2365 - val_mae: 38.8353\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1383.9443 - mae: 35.7451 - val_loss: 1496.5420 - val_mae: 38.6841\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1359.6403 - mae: 35.4395 - val_loss: 1480.4971 - val_mae: 38.4755\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1340.4595 - mae: 35.1149 - val_loss: 1462.0627 - val_mae: 38.2343\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1306.3674 - mae: 34.6408 - val_loss: 1436.0192 - val_mae: 37.8905\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1267.8677 - mae: 34.0846 - val_loss: 1404.4150 - val_mae: 37.4687\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1224.6696 - mae: 33.4288 - val_loss: 1364.4102 - val_mae: 36.9269\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1178.0503 - mae: 32.7165 - val_loss: 1314.6702 - val_mae: 36.2405\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1132.2858 - mae: 31.9070 - val_loss: 1257.6111 - val_mae: 35.4348\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1059.8159 - mae: 30.8525 - val_loss: 1188.0460 - val_mae: 34.4239\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1006.4341 - mae: 29.8789 - val_loss: 1108.1499 - val_mae: 33.2202\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 933.8930 - mae: 28.5486 - val_loss: 1015.4540 - val_mae: 31.7590\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 872.9709 - mae: 27.3862 - val_loss: 918.6658 - val_mae: 30.1483\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 820.5145 - mae: 26.1380 - val_loss: 813.8759 - val_mae: 28.2871\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 710.9631 - mae: 24.1842 - val_loss: 706.9730 - val_mae: 26.2338\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 638.9477 - mae: 22.5757 - val_loss: 598.5539 - val_mae: 23.9452\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 567.1768 - mae: 20.9770 - val_loss: 492.4749 - val_mae: 21.4324\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 524.3219 - mae: 19.6137 - val_loss: 397.7885 - val_mae: 18.8597\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 465.9865 - mae: 18.2884 - val_loss: 317.1383 - val_mae: 16.2926\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 391.9511 - mae: 16.6501 - val_loss: 252.2290 - val_mae: 13.8205\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 413.9625 - mae: 16.7641 - val_loss: 202.5084 - val_mae: 11.5056\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 370.9631 - mae: 15.3800 - val_loss: 166.7300 - val_mae: 9.4451\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 329.4018 - mae: 14.6185 - val_loss: 142.2424 - val_mae: 9.0985\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 305.7515 - mae: 14.2282 - val_loss: 125.9165 - val_mae: 9.2205\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 282.4363 - mae: 13.7470 - val_loss: 114.4466 - val_mae: 9.2089\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 266.6201 - mae: 13.2226 - val_loss: 105.9376 - val_mae: 9.0754\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 310.7455 - mae: 13.9741 - val_loss: 98.9675 - val_mae: 8.8454\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 255.9534 - mae: 12.8281 - val_loss: 92.9623 - val_mae: 8.5766\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 271.9795 - mae: 13.1069 - val_loss: 87.5614 - val_mae: 8.2771\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 296.3293 - mae: 13.6924 - val_loss: 83.0553 - val_mae: 7.9690\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 240.3882 - mae: 12.5288 - val_loss: 78.6606 - val_mae: 7.6792\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 265.9934 - mae: 12.5839 - val_loss: 74.6948 - val_mae: 7.3987\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 275.9892 - mae: 12.8934 - val_loss: 71.0956 - val_mae: 7.1342\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 247.7495 - mae: 12.2907 - val_loss: 66.9726 - val_mae: 6.9008\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 246.4111 - mae: 12.2307 - val_loss: 63.5420 - val_mae: 6.6616\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 268.8775 - mae: 12.8209 - val_loss: 60.0560 - val_mae: 6.4386\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 268.4514 - mae: 12.7548 - val_loss: 56.5827 - val_mae: 6.2316\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 239.1721 - mae: 12.1598 - val_loss: 53.6552 - val_mae: 6.0212\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 215.5896 - mae: 11.7400 - val_loss: 50.8682 - val_mae: 5.8163\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 223.5616 - mae: 11.6947 - val_loss: 47.9694 - val_mae: 5.6235\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 225.4546 - mae: 11.2229 - val_loss: 44.5975 - val_mae: 5.4506\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 231.0495 - mae: 11.8403 - val_loss: 41.4381 - val_mae: 5.2801\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 215.7360 - mae: 11.4366 - val_loss: 39.7149 - val_mae: 5.0761\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 215.6208 - mae: 11.2889 - val_loss: 38.1323 - val_mae: 4.8731\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 228.3920 - mae: 11.5501 - val_loss: 36.8436 - val_mae: 4.6730\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 209.6670 - mae: 11.2041 - val_loss: 36.0663 - val_mae: 4.4721\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 203.8663 - mae: 10.9346 - val_loss: 35.2805 - val_mae: 4.2801\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 210.7608 - mae: 10.9846 - val_loss: 34.2393 - val_mae: 4.1698\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 206.3098 - mae: 11.1875 - val_loss: 32.6267 - val_mae: 4.1253\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 215.5214 - mae: 10.8370 - val_loss: 31.2029 - val_mae: 4.0944\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 213.1011 - mae: 10.9771 - val_loss: 29.4363 - val_mae: 4.0113\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 222.8626 - mae: 11.1300 - val_loss: 28.8510 - val_mae: 4.0819\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 186.6953 - mae: 10.1929 - val_loss: 29.1046 - val_mae: 4.2496\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 198.9380 - mae: 10.8298 - val_loss: 29.4412 - val_mae: 4.4050\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 172.8982 - mae: 10.0152 - val_loss: 28.8721 - val_mae: 4.4355\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 213.2587 - mae: 10.6858 - val_loss: 27.3226 - val_mae: 4.3380\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 176.7653 - mae: 9.6801 - val_loss: 26.4971 - val_mae: 4.3224\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 239.1445 - mae: 11.2564 - val_loss: 25.7446 - val_mae: 4.3092\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 177.3236 - mae: 10.0659 - val_loss: 25.4813 - val_mae: 4.3498\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 190.6382 - mae: 10.1549 - val_loss: 24.8647 - val_mae: 4.3441\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 161.5970 - mae: 9.8473 - val_loss: 25.1410 - val_mae: 4.4394\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 187.6936 - mae: 10.3710 - val_loss: 24.4855 - val_mae: 4.4205\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 173.3518 - mae: 9.9801 - val_loss: 24.5995 - val_mae: 4.4856\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 186.2036 - mae: 9.8427 - val_loss: 24.3593 - val_mae: 4.5050\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 184.8535 - mae: 10.1206 - val_loss: 24.7880 - val_mae: 4.5963\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 172.7319 - mae: 9.9592 - val_loss: 24.6898 - val_mae: 4.6236\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 175.3042 - mae: 9.9740 - val_loss: 25.0094 - val_mae: 4.6935\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 164.3914 - mae: 9.3613 - val_loss: 26.0281 - val_mae: 4.8328\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 218.4606 - mae: 10.7612 - val_loss: 27.2411 - val_mae: 4.9850\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 7s 421ms/step - loss: 1467.7648 - mae: 36.8843 - val_loss: 1934.6729 - val_mae: 43.9849\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1466.3060 - mae: 36.8648 - val_loss: 1932.9016 - val_mae: 43.9648\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 1464.4235 - mae: 36.8398 - val_loss: 1931.1467 - val_mae: 43.9448\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1462.5704 - mae: 36.8138 - val_loss: 1929.2769 - val_mae: 43.9235\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1459.8676 - mae: 36.7785 - val_loss: 1927.1182 - val_mae: 43.8989\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1457.6421 - mae: 36.7473 - val_loss: 1924.7219 - val_mae: 43.8716\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1454.6862 - mae: 36.7080 - val_loss: 1921.5613 - val_mae: 43.8356\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1451.5692 - mae: 36.6645 - val_loss: 1917.9172 - val_mae: 43.7940\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1446.1638 - mae: 36.5926 - val_loss: 1913.3345 - val_mae: 43.7416\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1442.2938 - mae: 36.5405 - val_loss: 1907.4152 - val_mae: 43.6738\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1437.3834 - mae: 36.4724 - val_loss: 1900.8748 - val_mae: 43.5988\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1428.3627 - mae: 36.3524 - val_loss: 1891.9087 - val_mae: 43.4958\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1420.4250 - mae: 36.2428 - val_loss: 1881.6532 - val_mae: 43.3775\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1409.6953 - mae: 36.0934 - val_loss: 1868.4033 - val_mae: 43.2243\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1397.3600 - mae: 35.9256 - val_loss: 1852.7039 - val_mae: 43.0419\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1376.3785 - mae: 35.6406 - val_loss: 1830.6351 - val_mae: 42.7841\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1353.6357 - mae: 35.3194 - val_loss: 1801.9224 - val_mae: 42.4460\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1327.5979 - mae: 34.9341 - val_loss: 1767.9736 - val_mae: 42.0426\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1289.7317 - mae: 34.3992 - val_loss: 1721.5791 - val_mae: 41.4843\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1247.0687 - mae: 33.7553 - val_loss: 1663.0027 - val_mae: 40.7674\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1193.3110 - mae: 32.9796 - val_loss: 1592.1721 - val_mae: 39.8817\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1129.6232 - mae: 31.9237 - val_loss: 1510.8009 - val_mae: 38.8372\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1068.6222 - mae: 30.9246 - val_loss: 1410.7505 - val_mae: 37.5091\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 982.4595 - mae: 29.4773 - val_loss: 1287.3179 - val_mae: 35.7951\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 882.0351 - mae: 27.6484 - val_loss: 1155.3501 - val_mae: 33.8565\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 787.2676 - mae: 25.8015 - val_loss: 1005.3844 - val_mae: 31.4909\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 675.9325 - mae: 23.5738 - val_loss: 846.8032 - val_mae: 28.7478\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 568.3664 - mae: 21.1617 - val_loss: 689.6984 - val_mae: 25.7070\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 482.9640 - mae: 19.1830 - val_loss: 543.1444 - val_mae: 22.4728\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 424.4869 - mae: 17.6184 - val_loss: 416.4752 - val_mae: 19.2334\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 343.4154 - mae: 15.5707 - val_loss: 314.0509 - val_mae: 16.1171\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 292.3124 - mae: 14.1405 - val_loss: 237.0588 - val_mae: 13.3146\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 299.2250 - mae: 14.2391 - val_loss: 182.5780 - val_mae: 11.0067\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 271.7914 - mae: 13.3862 - val_loss: 146.8363 - val_mae: 9.4155\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 238.8179 - mae: 12.5650 - val_loss: 124.9200 - val_mae: 8.6033\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 251.9783 - mae: 12.6760 - val_loss: 111.3218 - val_mae: 8.3203\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 231.5099 - mae: 12.1041 - val_loss: 101.7078 - val_mae: 8.2459\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 209.3022 - mae: 11.5745 - val_loss: 96.3406 - val_mae: 8.3905\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 196.0744 - mae: 11.2737 - val_loss: 94.9804 - val_mae: 8.6968\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 196.9488 - mae: 10.9763 - val_loss: 93.3499 - val_mae: 8.8867\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 160.7133 - mae: 10.2639 - val_loss: 93.3184 - val_mae: 9.0994\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 174.0204 - mae: 10.4231 - val_loss: 91.9048 - val_mae: 9.1788\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 168.1593 - mae: 10.2379 - val_loss: 87.2454 - val_mae: 9.0361\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 172.1604 - mae: 10.3724 - val_loss: 83.7717 - val_mae: 8.9313\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 163.9940 - mae: 9.9514 - val_loss: 84.1077 - val_mae: 9.0207\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 155.9180 - mae: 9.6124 - val_loss: 85.1826 - val_mae: 9.1303\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 143.0417 - mae: 9.4356 - val_loss: 84.6009 - val_mae: 9.1331\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 175.2555 - mae: 10.4867 - val_loss: 84.8741 - val_mae: 9.1722\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 141.9989 - mae: 9.1062 - val_loss: 86.8953 - val_mae: 9.2986\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 6s 408ms/step - loss: 1468.4417 - mae: 36.8993 - val_loss: 120.6242 - val_mae: 10.9829\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1466.6954 - mae: 36.8760 - val_loss: 120.1055 - val_mae: 10.9593\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1465.0439 - mae: 36.8533 - val_loss: 119.4511 - val_mae: 10.9294\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1463.1749 - mae: 36.8279 - val_loss: 118.7124 - val_mae: 10.8955\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1461.2625 - mae: 36.8023 - val_loss: 117.9355 - val_mae: 10.8598\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1458.5659 - mae: 36.7662 - val_loss: 117.0830 - val_mae: 10.8205\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1455.8324 - mae: 36.7281 - val_loss: 116.1066 - val_mae: 10.7753\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1452.4132 - mae: 36.6832 - val_loss: 115.0041 - val_mae: 10.7240\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1448.7308 - mae: 36.6333 - val_loss: 113.6889 - val_mae: 10.6625\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1444.1624 - mae: 36.5719 - val_loss: 112.1184 - val_mae: 10.5886\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1437.4113 - mae: 36.4801 - val_loss: 110.1610 - val_mae: 10.4958\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1429.9940 - mae: 36.3782 - val_loss: 107.8032 - val_mae: 10.3828\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1420.2292 - mae: 36.2432 - val_loss: 104.8113 - val_mae: 10.2377\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1407.4329 - mae: 36.0787 - val_loss: 101.0885 - val_mae: 10.0543\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 1394.0165 - mae: 35.8795 - val_loss: 96.5828 - val_mae: 9.8276\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 1376.8928 - mae: 35.6428 - val_loss: 90.9527 - val_mae: 9.5368\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 1349.7865 - mae: 35.2711 - val_loss: 84.1742 - val_mae: 9.1743\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1317.6824 - mae: 34.8110 - val_loss: 76.2405 - val_mae: 8.7306\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 1282.8895 - mae: 34.2931 - val_loss: 67.0622 - val_mae: 8.1869\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 1234.5299 - mae: 33.6043 - val_loss: 56.0085 - val_mae: 7.4787\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1184.7045 - mae: 32.7920 - val_loss: 43.7841 - val_mae: 6.6055\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 1128.0646 - mae: 31.9327 - val_loss: 31.0215 - val_mae: 5.5443\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 1051.4106 - mae: 30.6426 - val_loss: 19.2750 - val_mae: 4.3339\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 973.1237 - mae: 29.3089 - val_loss: 9.0109 - val_mae: 2.8594\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 898.0789 - mae: 27.9646 - val_loss: 2.8995 - val_mae: 1.2537\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 790.8964 - mae: 25.9465 - val_loss: 2.6544 - val_mae: 1.4452\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 702.7256 - mae: 24.0397 - val_loss: 11.0570 - val_mae: 2.8269\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 623.5269 - mae: 22.1900 - val_loss: 31.0747 - val_mae: 5.1687\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 523.1547 - mae: 20.0435 - val_loss: 66.3696 - val_mae: 7.7719\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 419.7133 - mae: 17.4002 - val_loss: 119.8202 - val_mae: 10.5848\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 353.3260 - mae: 15.8257 - val_loss: 186.3021 - val_mae: 13.3021\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 9s 527ms/step - loss: 1470.3333 - mae: 36.9282 - val_loss: 419.7029 - val_mae: 20.4866\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 1468.9324 - mae: 36.9099 - val_loss: 418.8077 - val_mae: 20.4648\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1467.4384 - mae: 36.8892 - val_loss: 417.9249 - val_mae: 20.4431\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 1465.8789 - mae: 36.8679 - val_loss: 417.0598 - val_mae: 20.4219\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1464.0436 - mae: 36.8433 - val_loss: 416.1023 - val_mae: 20.3984\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1462.3025 - mae: 36.8182 - val_loss: 415.0298 - val_mae: 20.3721\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 1459.6990 - mae: 36.7855 - val_loss: 413.7626 - val_mae: 20.3408\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 1457.1133 - mae: 36.7487 - val_loss: 412.4043 - val_mae: 20.3073\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1454.2712 - mae: 36.7108 - val_loss: 410.8258 - val_mae: 20.2682\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1450.3318 - mae: 36.6570 - val_loss: 408.9746 - val_mae: 20.2223\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 1444.9165 - mae: 36.5840 - val_loss: 406.6115 - val_mae: 20.1635\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 1439.8170 - mae: 36.5137 - val_loss: 403.7352 - val_mae: 20.0917\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 1431.6422 - mae: 36.4051 - val_loss: 400.1951 - val_mae: 20.0027\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 1422.1302 - mae: 36.2767 - val_loss: 395.8397 - val_mae: 19.8925\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1413.2659 - mae: 36.1484 - val_loss: 390.6977 - val_mae: 19.7613\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1394.5367 - mae: 35.9023 - val_loss: 383.7841 - val_mae: 19.5831\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1375.9058 - mae: 35.6328 - val_loss: 374.9858 - val_mae: 19.3531\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 1353.5194 - mae: 35.3174 - val_loss: 364.3579 - val_mae: 19.0703\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 1319.1516 - mae: 34.8303 - val_loss: 350.0390 - val_mae: 18.6806\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 1282.7844 - mae: 34.2689 - val_loss: 333.0912 - val_mae: 18.2049\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 1242.5280 - mae: 33.6521 - val_loss: 311.0675 - val_mae: 17.5609\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 1191.3781 - mae: 32.8195 - val_loss: 285.0536 - val_mae: 16.7567\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1128.3484 - mae: 31.8665 - val_loss: 253.9018 - val_mae: 15.7189\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 1055.0978 - mae: 30.6280 - val_loss: 218.4849 - val_mae: 14.4111\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 965.2656 - mae: 28.9255 - val_loss: 179.3316 - val_mae: 12.7425\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 867.4565 - mae: 27.1342 - val_loss: 140.5171 - val_mae: 10.7290\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 796.6759 - mae: 25.6637 - val_loss: 106.4999 - val_mae: 8.3852\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 711.7433 - mae: 23.8046 - val_loss: 82.1974 - val_mae: 6.9926\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 594.0763 - mae: 21.2993 - val_loss: 71.6246 - val_mae: 7.9563\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 537.6487 - mae: 19.9238 - val_loss: 78.6906 - val_mae: 8.8686\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 465.0031 - mae: 18.2347 - val_loss: 103.9493 - val_mae: 9.6411\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 418.0381 - mae: 17.0725 - val_loss: 142.7109 - val_mae: 10.1740\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 357.6684 - mae: 15.7400 - val_loss: 185.8585 - val_mae: 10.3691\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 323.9653 - mae: 14.8792 - val_loss: 223.9494 - val_mae: 10.9369\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 6s 446ms/step - loss: 1233.2413 - mae: 33.7587 - val_loss: 989.7814 - val_mae: 31.4608\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1231.3242 - mae: 33.7307 - val_loss: 988.0378 - val_mae: 31.4331\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1229.0029 - mae: 33.6965 - val_loss: 986.1708 - val_mae: 31.4034\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 1226.3850 - mae: 33.6566 - val_loss: 984.1460 - val_mae: 31.3711\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1222.9592 - mae: 33.6059 - val_loss: 981.8163 - val_mae: 31.3339\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 1220.2064 - mae: 33.5661 - val_loss: 979.2537 - val_mae: 31.2930\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1216.7377 - mae: 33.5149 - val_loss: 976.3809 - val_mae: 31.2471\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1211.9033 - mae: 33.4423 - val_loss: 973.0513 - val_mae: 31.1938\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 1206.6632 - mae: 33.3681 - val_loss: 969.1819 - val_mae: 31.1317\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 1201.2305 - mae: 33.2810 - val_loss: 964.8531 - val_mae: 31.0621\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 1192.1615 - mae: 33.1459 - val_loss: 959.5883 - val_mae: 30.9772\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 1184.8951 - mae: 33.0311 - val_loss: 953.5374 - val_mae: 30.8794\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 1172.3829 - mae: 32.8414 - val_loss: 946.1652 - val_mae: 30.7597\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 1160.0005 - mae: 32.6587 - val_loss: 937.8372 - val_mae: 30.6240\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 1143.2472 - mae: 32.3767 - val_loss: 927.7817 - val_mae: 30.4594\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 1122.9681 - mae: 32.0807 - val_loss: 915.7799 - val_mae: 30.2616\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 1108.3978 - mae: 31.8007 - val_loss: 901.1918 - val_mae: 30.0195\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 1076.0104 - mae: 31.2874 - val_loss: 883.6044 - val_mae: 29.7250\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 1031.0331 - mae: 30.5374 - val_loss: 862.7571 - val_mae: 29.3720\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 92ms/step - loss: 1008.8090 - mae: 30.1521 - val_loss: 838.7079 - val_mae: 28.9595\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 102ms/step - loss: 962.7518 - mae: 29.3191 - val_loss: 810.1246 - val_mae: 28.4612\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 910.7408 - mae: 28.3083 - val_loss: 775.1149 - val_mae: 27.8387\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 854.3742 - mae: 27.2596 - val_loss: 735.9081 - val_mae: 27.1245\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 802.5830 - mae: 26.3367 - val_loss: 690.3049 - val_mae: 26.2690\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 106ms/step - loss: 731.3937 - mae: 24.6628 - val_loss: 636.8668 - val_mae: 25.2293\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 667.1806 - mae: 23.1720 - val_loss: 576.7563 - val_mae: 24.0055\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 592.6996 - mae: 21.7500 - val_loss: 510.7908 - val_mae: 22.5856\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 532.4783 - mae: 20.1087 - val_loss: 438.1656 - val_mae: 20.9098\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 473.5803 - mae: 18.8295 - val_loss: 365.4420 - val_mae: 19.0833\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 417.7783 - mae: 17.1800 - val_loss: 294.3695 - val_mae: 17.1089\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 352.4691 - mae: 15.6876 - val_loss: 229.1482 - val_mae: 15.0691\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 308.4135 - mae: 14.7084 - val_loss: 175.2295 - val_mae: 13.1447\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 281.8386 - mae: 14.1526 - val_loss: 132.3690 - val_mae: 11.3858\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 283.7585 - mae: 14.3416 - val_loss: 102.0861 - val_mae: 9.9610\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 248.5250 - mae: 12.9923 - val_loss: 81.7512 - val_mae: 8.8829\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 230.8387 - mae: 12.5506 - val_loss: 68.1417 - val_mae: 8.0900\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 201.9233 - mae: 11.5016 - val_loss: 56.4219 - val_mae: 7.3422\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 189.8037 - mae: 11.2595 - val_loss: 48.6752 - val_mae: 6.8117\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 201.8869 - mae: 11.3661 - val_loss: 42.3499 - val_mae: 6.3487\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 198.1681 - mae: 11.2104 - val_loss: 39.6041 - val_mae: 6.1491\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 182.9372 - mae: 10.8988 - val_loss: 35.9251 - val_mae: 5.8597\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 161.8144 - mae: 10.4820 - val_loss: 31.5227 - val_mae: 5.4873\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 188.3358 - mae: 11.2823 - val_loss: 26.7375 - val_mae: 5.0465\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 168.6990 - mae: 10.3206 - val_loss: 22.3417 - val_mae: 4.6059\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 152.7410 - mae: 9.8922 - val_loss: 20.1336 - val_mae: 4.3875\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 159.8526 - mae: 10.2998 - val_loss: 17.6487 - val_mae: 4.1206\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 153.2778 - mae: 9.8062 - val_loss: 16.9833 - val_mae: 4.0643\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 172.2085 - mae: 10.2039 - val_loss: 16.2912 - val_mae: 3.9980\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 150.8936 - mae: 9.8381 - val_loss: 15.7926 - val_mae: 3.9503\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 151.2638 - mae: 9.7785 - val_loss: 13.3599 - val_mae: 3.6401\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 161.5971 - mae: 10.0409 - val_loss: 11.5539 - val_mae: 3.3901\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 135.4742 - mae: 9.3924 - val_loss: 10.8043 - val_mae: 3.2823\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 123.9252 - mae: 8.6873 - val_loss: 9.9566 - val_mae: 3.1530\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 145.0784 - mae: 9.5335 - val_loss: 7.7533 - val_mae: 2.7831\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 160.0287 - mae: 9.9071 - val_loss: 6.0759 - val_mae: 2.4641\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 140.5852 - mae: 9.4272 - val_loss: 5.0582 - val_mae: 2.2485\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 145.0866 - mae: 9.7272 - val_loss: 3.6500 - val_mae: 1.9101\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 121.3215 - mae: 8.8332 - val_loss: 2.9336 - val_mae: 1.7124\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 155.1783 - mae: 9.6979 - val_loss: 2.8795 - val_mae: 1.6965\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 120.3429 - mae: 8.6467 - val_loss: 2.7972 - val_mae: 1.6721\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 134.0528 - mae: 9.1732 - val_loss: 2.4149 - val_mae: 1.5537\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 127.5662 - mae: 8.9692 - val_loss: 1.7145 - val_mae: 1.3093\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 128.4049 - mae: 9.0127 - val_loss: 1.2966 - val_mae: 1.1386\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 127.6130 - mae: 9.0164 - val_loss: 1.2470 - val_mae: 1.1165\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 135.4753 - mae: 9.0317 - val_loss: 1.1622 - val_mae: 1.0778\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 134.0566 - mae: 8.9512 - val_loss: 0.7803 - val_mae: 0.8830\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 128.9095 - mae: 9.1058 - val_loss: 0.9159 - val_mae: 0.9566\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 103.8094 - mae: 8.1540 - val_loss: 0.7047 - val_mae: 0.8393\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 127.1258 - mae: 8.8258 - val_loss: 0.7095 - val_mae: 0.8422\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 118.3204 - mae: 8.4599 - val_loss: 0.9389 - val_mae: 0.9689\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 124.7077 - mae: 8.5570 - val_loss: 1.6156 - val_mae: 1.2710\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 138.0724 - mae: 9.4384 - val_loss: 1.8920 - val_mae: 1.3755\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 119.6735 - mae: 8.9021 - val_loss: 1.8479 - val_mae: 1.3593\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 6s 451ms/step - loss: 1233.9001 - mae: 33.7751 - val_loss: 2209.0552 - val_mae: 47.0006\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 1232.9579 - mae: 33.7610 - val_loss: 2208.1526 - val_mae: 46.9910\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1232.5394 - mae: 33.7547 - val_loss: 2207.6099 - val_mae: 46.9852\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1232.1537 - mae: 33.7490 - val_loss: 2207.0847 - val_mae: 46.9796\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1231.7244 - mae: 33.7427 - val_loss: 2206.5034 - val_mae: 46.9734\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 1231.3435 - mae: 33.7371 - val_loss: 2205.8735 - val_mae: 46.9667\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1230.8525 - mae: 33.7298 - val_loss: 2205.1912 - val_mae: 46.9595\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1230.3822 - mae: 33.7229 - val_loss: 2204.4727 - val_mae: 46.9518\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 1229.8534 - mae: 33.7150 - val_loss: 2203.7017 - val_mae: 46.9436\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1229.1481 - mae: 33.7048 - val_loss: 2202.8335 - val_mae: 46.9344\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 1228.6578 - mae: 33.6972 - val_loss: 2201.9006 - val_mae: 46.9244\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1227.8173 - mae: 33.6851 - val_loss: 2200.8594 - val_mae: 46.9133\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 1227.0117 - mae: 33.6727 - val_loss: 2199.6792 - val_mae: 46.9007\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 1225.9786 - mae: 33.6580 - val_loss: 2198.3323 - val_mae: 46.8864\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 1225.0481 - mae: 33.6438 - val_loss: 2196.7983 - val_mae: 46.8700\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 1223.7118 - mae: 33.6243 - val_loss: 2194.9890 - val_mae: 46.8507\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1221.5054 - mae: 33.5923 - val_loss: 2192.7463 - val_mae: 46.8268\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 1219.6168 - mae: 33.5630 - val_loss: 2189.9883 - val_mae: 46.7973\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 1216.7141 - mae: 33.5179 - val_loss: 2186.6648 - val_mae: 46.7618\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 1213.9086 - mae: 33.4807 - val_loss: 2182.5632 - val_mae: 46.7179\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 1209.3348 - mae: 33.4089 - val_loss: 2177.3081 - val_mae: 46.6616\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 1203.2523 - mae: 33.3160 - val_loss: 2170.3098 - val_mae: 46.5866\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 1195.7791 - mae: 33.2005 - val_loss: 2161.3140 - val_mae: 46.4899\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 1188.4409 - mae: 33.0963 - val_loss: 2150.6353 - val_mae: 46.3749\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 1177.1453 - mae: 32.9218 - val_loss: 2136.3818 - val_mae: 46.2209\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 1166.7615 - mae: 32.7663 - val_loss: 2117.7983 - val_mae: 46.0194\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1147.3173 - mae: 32.4484 - val_loss: 2094.4309 - val_mae: 45.7647\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 1123.1238 - mae: 32.0887 - val_loss: 2064.9561 - val_mae: 45.4414\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 1105.9652 - mae: 31.8391 - val_loss: 2028.4446 - val_mae: 45.0377\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 1068.9772 - mae: 31.1842 - val_loss: 1983.8269 - val_mae: 44.5393\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 1046.2263 - mae: 30.8732 - val_loss: 1930.1760 - val_mae: 43.9325\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 997.3581 - mae: 29.9912 - val_loss: 1868.0703 - val_mae: 43.2193\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 963.6927 - mae: 29.4562 - val_loss: 1797.3098 - val_mae: 42.3919\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 908.5175 - mae: 28.5528 - val_loss: 1714.8054 - val_mae: 41.4062\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 864.1905 - mae: 27.5904 - val_loss: 1624.0005 - val_mae: 40.2933\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 805.2900 - mae: 26.6549 - val_loss: 1526.5442 - val_mae: 39.0633\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 757.7556 - mae: 25.5684 - val_loss: 1421.6887 - val_mae: 37.6947\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 677.8782 - mae: 23.9116 - val_loss: 1310.9867 - val_mae: 36.1934\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 650.8226 - mae: 23.2342 - val_loss: 1199.3643 - val_mae: 34.6134\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 578.8549 - mae: 21.6090 - val_loss: 1087.0065 - val_mae: 32.9460\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 535.7242 - mae: 20.4503 - val_loss: 977.3993 - val_mae: 31.2333\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 483.0305 - mae: 18.8840 - val_loss: 873.9120 - val_mae: 29.5248\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 397.9849 - mae: 17.0555 - val_loss: 773.6132 - val_mae: 27.7685\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 379.7771 - mae: 16.3980 - val_loss: 679.3171 - val_mae: 26.0089\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 318.2436 - mae: 14.5462 - val_loss: 592.3644 - val_mae: 24.2735\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 259.2161 - mae: 13.2215 - val_loss: 514.5376 - val_mae: 22.6078\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 259.7682 - mae: 12.8634 - val_loss: 446.3640 - val_mae: 21.0414\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 224.7787 - mae: 11.7811 - val_loss: 388.7985 - val_mae: 19.6227\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 209.4366 - mae: 11.0107 - val_loss: 342.4193 - val_mae: 18.4026\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 248.8923 - mae: 11.8374 - val_loss: 305.7703 - val_mae: 17.3807\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 223.3613 - mae: 11.0130 - val_loss: 279.4887 - val_mae: 16.6130\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 168.4144 - mae: 9.8084 - val_loss: 260.2822 - val_mae: 16.0327\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 221.1541 - mae: 10.8190 - val_loss: 247.3406 - val_mae: 15.6338\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 216.8756 - mae: 11.0581 - val_loss: 240.0372 - val_mae: 15.4092\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 235.0012 - mae: 11.2561 - val_loss: 236.7628 - val_mae: 15.3135\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 213.3883 - mae: 10.7653 - val_loss: 236.6390 - val_mae: 15.3198\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 185.9722 - mae: 10.1138 - val_loss: 237.1055 - val_mae: 15.3442\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 205.7758 - mae: 10.4537 - val_loss: 237.8482 - val_mae: 15.3764\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 231.4649 - mae: 11.0719 - val_loss: 238.2241 - val_mae: 15.3955\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 197.8393 - mae: 10.6439 - val_loss: 236.6288 - val_mae: 15.3494\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 238.4256 - mae: 11.1861 - val_loss: 237.1976 - val_mae: 15.3731\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 204.1667 - mae: 10.3070 - val_loss: 237.2493 - val_mae: 15.3792\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 241.3723 - mae: 11.0597 - val_loss: 238.8576 - val_mae: 15.4352\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 167.9249 - mae: 9.7024 - val_loss: 238.7285 - val_mae: 15.4341\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 209.0143 - mae: 10.9826 - val_loss: 239.4378 - val_mae: 15.4598\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 9s 464ms/step - loss: 1232.2146 - mae: 33.7561 - val_loss: 929.4114 - val_mae: 30.4862\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1231.0817 - mae: 33.7394 - val_loss: 928.2667 - val_mae: 30.4675\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1229.9041 - mae: 33.7219 - val_loss: 927.1097 - val_mae: 30.4485\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 1228.4958 - mae: 33.7012 - val_loss: 925.8513 - val_mae: 30.4278\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1227.4039 - mae: 33.6847 - val_loss: 924.4681 - val_mae: 30.4050\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1225.6031 - mae: 33.6590 - val_loss: 922.8638 - val_mae: 30.3786\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1223.8025 - mae: 33.6321 - val_loss: 921.0016 - val_mae: 30.3480\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1222.1697 - mae: 33.6081 - val_loss: 918.8131 - val_mae: 30.3119\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1219.5830 - mae: 33.5695 - val_loss: 916.2630 - val_mae: 30.2697\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1217.1660 - mae: 33.5330 - val_loss: 913.1107 - val_mae: 30.2175\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1213.0598 - mae: 33.4740 - val_loss: 909.4194 - val_mae: 30.1563\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1208.8822 - mae: 33.4089 - val_loss: 904.7637 - val_mae: 30.0788\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 1202.9270 - mae: 33.3239 - val_loss: 898.6842 - val_mae: 29.9774\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1194.8994 - mae: 33.1992 - val_loss: 891.0049 - val_mae: 29.8485\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 1185.7382 - mae: 33.0674 - val_loss: 881.6010 - val_mae: 29.6898\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 1172.4795 - mae: 32.8593 - val_loss: 869.4816 - val_mae: 29.4837\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 1158.1152 - mae: 32.6409 - val_loss: 854.3545 - val_mae: 29.2239\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 1138.5695 - mae: 32.3264 - val_loss: 835.9952 - val_mae: 28.9045\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 1110.8501 - mae: 31.8813 - val_loss: 812.1128 - val_mae: 28.4821\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 1082.7107 - mae: 31.4213 - val_loss: 782.2584 - val_mae: 27.9426\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 1047.4731 - mae: 30.8610 - val_loss: 744.1519 - val_mae: 27.2339\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 1005.3888 - mae: 30.0598 - val_loss: 701.3768 - val_mae: 26.4085\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 953.6193 - mae: 29.1518 - val_loss: 649.7885 - val_mae: 25.3659\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 902.7098 - mae: 28.0969 - val_loss: 591.9642 - val_mae: 24.1256\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 841.5276 - mae: 26.9005 - val_loss: 527.9667 - val_mae: 22.6460\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 776.5001 - mae: 25.5677 - val_loss: 458.1069 - val_mae: 20.8671\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 705.6122 - mae: 24.2238 - val_loss: 389.3388 - val_mae: 18.8908\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 656.4786 - mae: 23.0714 - val_loss: 325.2143 - val_mae: 16.7557\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 606.5007 - mae: 21.7380 - val_loss: 270.3292 - val_mae: 14.6009\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 528.5870 - mae: 19.9710 - val_loss: 223.6736 - val_mae: 12.4232\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 471.6313 - mae: 18.5925 - val_loss: 186.6632 - val_mae: 10.3742\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 450.2514 - mae: 17.9116 - val_loss: 157.4137 - val_mae: 9.2555\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 404.3612 - mae: 17.0762 - val_loss: 134.2595 - val_mae: 9.3990\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 372.2711 - mae: 16.2438 - val_loss: 115.4280 - val_mae: 9.2714\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 351.7482 - mae: 15.7140 - val_loss: 99.9034 - val_mae: 9.0754\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 319.1489 - mae: 14.8276 - val_loss: 86.3207 - val_mae: 8.7049\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 302.6519 - mae: 14.4724 - val_loss: 74.1283 - val_mae: 8.2158\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 281.4383 - mae: 13.6532 - val_loss: 62.9134 - val_mae: 7.6422\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 280.0236 - mae: 13.6421 - val_loss: 52.7657 - val_mae: 7.0154\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 255.3577 - mae: 12.9192 - val_loss: 44.1467 - val_mae: 6.4667\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 220.1093 - mae: 11.9471 - val_loss: 36.5901 - val_mae: 5.9381\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 222.1536 - mae: 12.1106 - val_loss: 30.3909 - val_mae: 5.4594\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 209.4060 - mae: 11.4989 - val_loss: 25.0678 - val_mae: 4.9864\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 213.6355 - mae: 11.7104 - val_loss: 20.8422 - val_mae: 4.5648\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 213.8593 - mae: 11.7955 - val_loss: 17.3861 - val_mae: 4.1634\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 208.9916 - mae: 11.5318 - val_loss: 14.9093 - val_mae: 3.8144\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 168.1171 - mae: 10.3789 - val_loss: 12.9897 - val_mae: 3.4866\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 187.9057 - mae: 11.0505 - val_loss: 11.1209 - val_mae: 3.1472\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 170.5322 - mae: 10.4409 - val_loss: 9.2120 - val_mae: 2.8098\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 160.7145 - mae: 10.0891 - val_loss: 7.1272 - val_mae: 2.4702\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 165.4276 - mae: 10.2166 - val_loss: 5.3510 - val_mae: 2.1528\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 175.5818 - mae: 10.4255 - val_loss: 4.5399 - val_mae: 1.9206\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 153.5734 - mae: 9.9347 - val_loss: 3.7130 - val_mae: 1.6869\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 148.9650 - mae: 9.5873 - val_loss: 2.8538 - val_mae: 1.4798\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 149.5421 - mae: 9.6644 - val_loss: 2.1474 - val_mae: 1.2974\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 156.9804 - mae: 9.8596 - val_loss: 1.8934 - val_mae: 1.1636\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 174.7816 - mae: 10.3992 - val_loss: 1.7287 - val_mae: 1.0610\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 161.4796 - mae: 9.9709 - val_loss: 1.4284 - val_mae: 0.9628\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 181.2970 - mae: 10.6386 - val_loss: 1.3131 - val_mae: 0.8995\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 164.9736 - mae: 10.1700 - val_loss: 1.5025 - val_mae: 0.8753\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 165.2823 - mae: 10.2215 - val_loss: 1.8939 - val_mae: 1.1013\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 148.8777 - mae: 9.7296 - val_loss: 2.5659 - val_mae: 1.3846\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 160.3626 - mae: 10.0588 - val_loss: 3.5292 - val_mae: 1.7023\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 148.9975 - mae: 9.7538 - val_loss: 3.4834 - val_mae: 1.7160\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 7s 392ms/step - loss: 1236.9178 - mae: 33.8197 - val_loss: 991.9493 - val_mae: 31.4952\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1236.2644 - mae: 33.8101 - val_loss: 991.4548 - val_mae: 31.4874\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1235.6680 - mae: 33.8015 - val_loss: 990.9479 - val_mae: 31.4793\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1235.0951 - mae: 33.7928 - val_loss: 990.4124 - val_mae: 31.4708\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1234.2990 - mae: 33.7811 - val_loss: 989.8230 - val_mae: 31.4615\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1233.5701 - mae: 33.7703 - val_loss: 989.1865 - val_mae: 31.4513\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1232.9033 - mae: 33.7607 - val_loss: 988.4908 - val_mae: 31.4403\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1232.0078 - mae: 33.7470 - val_loss: 987.7301 - val_mae: 31.4282\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1230.9725 - mae: 33.7321 - val_loss: 986.8724 - val_mae: 31.4145\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1229.7212 - mae: 33.7123 - val_loss: 985.8738 - val_mae: 31.3986\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1228.5967 - mae: 33.6968 - val_loss: 984.7784 - val_mae: 31.3812\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1226.7063 - mae: 33.6686 - val_loss: 983.4894 - val_mae: 31.3606\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1224.6136 - mae: 33.6370 - val_loss: 982.0353 - val_mae: 31.3374\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1222.1292 - mae: 33.6000 - val_loss: 980.2814 - val_mae: 31.3094\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1219.1658 - mae: 33.5569 - val_loss: 978.2015 - val_mae: 31.2762\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1216.3984 - mae: 33.5125 - val_loss: 975.7611 - val_mae: 31.2372\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1211.8832 - mae: 33.4417 - val_loss: 972.7462 - val_mae: 31.1888\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1205.7103 - mae: 33.3558 - val_loss: 969.1978 - val_mae: 31.1319\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1200.5327 - mae: 33.2753 - val_loss: 964.8874 - val_mae: 31.0626\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1190.7324 - mae: 33.1239 - val_loss: 959.4416 - val_mae: 30.9748\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1181.4801 - mae: 32.9730 - val_loss: 952.8538 - val_mae: 30.8682\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1169.4611 - mae: 32.8050 - val_loss: 945.0426 - val_mae: 30.7413\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1158.5648 - mae: 32.6185 - val_loss: 935.1872 - val_mae: 30.5805\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1140.6359 - mae: 32.3516 - val_loss: 923.4575 - val_mae: 30.3879\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 1118.7367 - mae: 32.0031 - val_loss: 909.4347 - val_mae: 30.1560\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1111.2942 - mae: 31.8894 - val_loss: 893.5878 - val_mae: 29.8918\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 1073.5554 - mae: 31.2574 - val_loss: 874.2235 - val_mae: 29.5657\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1048.0128 - mae: 30.8349 - val_loss: 851.3632 - val_mae: 29.1759\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 1017.7554 - mae: 30.3605 - val_loss: 825.1520 - val_mae: 28.7224\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 988.9524 - mae: 29.8740 - val_loss: 796.5623 - val_mae: 28.2194\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 957.1994 - mae: 29.2928 - val_loss: 764.6255 - val_mae: 27.6466\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 922.0352 - mae: 28.6665 - val_loss: 729.1792 - val_mae: 26.9965\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 874.3204 - mae: 27.7686 - val_loss: 687.2645 - val_mae: 26.2067\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 812.8826 - mae: 26.7839 - val_loss: 643.5287 - val_mae: 25.3563\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 759.4237 - mae: 25.6748 - val_loss: 594.9169 - val_mae: 24.3766\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 715.2662 - mae: 24.7520 - val_loss: 540.6119 - val_mae: 23.2339\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 646.1645 - mae: 23.3254 - val_loss: 483.7794 - val_mae: 21.9746\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 616.6082 - mae: 22.5278 - val_loss: 423.8517 - val_mae: 20.5636\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 566.6278 - mae: 21.4032 - val_loss: 362.9961 - val_mae: 19.0241\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 497.8036 - mae: 19.8232 - val_loss: 300.3538 - val_mae: 17.2961\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 432.8397 - mae: 18.1181 - val_loss: 242.1087 - val_mae: 15.5183\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 405.1159 - mae: 16.7443 - val_loss: 188.0774 - val_mae: 13.6644\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 335.1386 - mae: 15.1315 - val_loss: 140.0181 - val_mae: 11.7739\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 297.6679 - mae: 14.0428 - val_loss: 99.1394 - val_mae: 9.8875\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 285.6181 - mae: 13.5997 - val_loss: 66.4222 - val_mae: 8.0699\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 248.3452 - mae: 12.2032 - val_loss: 41.9403 - val_mae: 6.3849\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 226.9003 - mae: 11.4512 - val_loss: 24.6773 - val_mae: 4.8641\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 225.9914 - mae: 11.1675 - val_loss: 13.5005 - val_mae: 3.5580\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 249.2397 - mae: 11.7834 - val_loss: 6.5027 - val_mae: 2.4158\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 237.3014 - mae: 11.3357 - val_loss: 2.9513 - val_mae: 1.5657\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 235.8662 - mae: 11.2724 - val_loss: 1.2869 - val_mae: 0.9710\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 198.4359 - mae: 10.5436 - val_loss: 0.5996 - val_mae: 0.6226\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 202.5741 - mae: 10.5529 - val_loss: 0.3776 - val_mae: 0.5122\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 173.6145 - mae: 9.9006 - val_loss: 0.2659 - val_mae: 0.4599\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 220.3149 - mae: 11.0152 - val_loss: 0.2775 - val_mae: 0.5084\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 231.9945 - mae: 11.0668 - val_loss: 0.3769 - val_mae: 0.6111\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 235.8145 - mae: 11.2555 - val_loss: 0.6230 - val_mae: 0.7893\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 204.2429 - mae: 10.5431 - val_loss: 0.8471 - val_mae: 0.9188\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 210.0086 - mae: 10.4873 - val_loss: 1.0384 - val_mae: 1.0144\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Index(...) must be called with a collection of some kind, 'Players' was passed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-319-6b5f82a20125>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mplayer_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplayer_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mplayer_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplayer_lst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mplayer_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'Players'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0mplayer_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0mkind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPOSITIONAL_OR_KEYWORD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mrename\u001b[0;34m(self, mapper, index, columns, axis, copy, inplace, level, errors)\u001b[0m\n\u001b[1;32m   4294\u001b[0m         \u001b[0;36m4\u001b[0m  \u001b[0;36m3\u001b[0m  \u001b[0;36m6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4295\u001b[0m         \"\"\"\n\u001b[0;32m-> 4296\u001b[0;31m         return super().rename(\n\u001b[0m\u001b[1;32m   4297\u001b[0m             \u001b[0mmapper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4298\u001b[0m             \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mrename\u001b[0;34m(self, mapper, index, columns, axis, copy, inplace, level, errors)\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0;31m# GH 13473\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplacements\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 938\u001b[0;31m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplacements\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    939\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"raise\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m                     missing_labels = [\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_indexer_for\u001b[0;34m(self, target, **kwargs)\u001b[0m\n\u001b[1;32m   4711\u001b[0m         \"\"\"\n\u001b[1;32m   4712\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4713\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4714\u001b[0m         \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4715\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   2960\u001b[0m     ) -> np.ndarray:\n\u001b[1;32m   2961\u001b[0m         \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_reindex_fill_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2962\u001b[0;31m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2963\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2964\u001b[0m             \u001b[0mtolerance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_tolerance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mensure_index\u001b[0;34m(index_like, copy)\u001b[0m\n\u001b[1;32m   5616\u001b[0m             \u001b[0mindex_like\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_like\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5618\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_like\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, data, dtype, copy, name, tupleize_cols, **kwargs)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scalar_data_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__array__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Index(...) must be called with a collection of some kind, 'Players' was passed"
     ]
    }
   ],
   "source": [
    "player_lst = ['Stephen Curry', 'LeBron James', 'Kevin Durant']\n",
    "date_range = pd.date_range(start= '2018-01-11', end = '2018-01-18')\n",
    "player_df = pd.DataFrame()\n",
    "   \n",
    "for player in player_lst:\n",
    "    data_df = df.loc[df['PLAYER_NAME'] == player]\n",
    "    data_df = data_df.iloc[:,4:-1].rolling(window=5).mean()\n",
    "    data_df['FTSY_PTS'] = df.loc[df['PLAYER_NAME']== player]['FTSY_PTS']\n",
    "    data_df.dropna(inplace= True)\n",
    "    \n",
    "    output_lst = []\n",
    "    for day in date_range:\n",
    "        if day in data_df.index:\n",
    "            X_train = data_df.loc['2015-10-02': day].drop(columns= 'FTSY_PTS')\n",
    "            X_train = X_train[:-1]\n",
    "            y_train = data_df.loc['2015-10-02': day]['FTSY_PTS']\n",
    "            y_train = y_train[:-1]\n",
    "            \n",
    "            day_ind = data_df.index.get_loc(day)\n",
    "            X_test = data_df.iloc[[day_ind,day_ind+1]].drop(columns = 'FTSY_PTS')\n",
    "            y_test = data_df.iloc[[day_ind,day_ind+1]]['FTSY_PTS']\n",
    "            \n",
    "            ss = StandardScaler()\n",
    "            X_train_sc = ss.fit_transform(X_train)\n",
    "            X_test_sc = ss.transform(X_test)\n",
    "\n",
    "            train_seq = TimeseriesGenerator(X_train_sc, y_train, length=1, batch_size=64)\n",
    "            test_seq = TimeseriesGenerator(X_test_sc, y_test, length = 1, batch_size=64)\n",
    "\n",
    "            model = Sequential()\n",
    "\n",
    "            model.add(LSTM(64, input_shape=(1,20), return_sequences=True))\n",
    "            model.add(LSTM(32, return_sequences=False))\n",
    "\n",
    "            model.add(Dense(32, activation= 'relu'))\n",
    "            model.add(Dropout(.1))\n",
    "\n",
    "            model.add(Dense(8, activation= 'relu'))\n",
    "            model.add(Dropout(.1))\n",
    "\n",
    "            model.add(Dense(2))\n",
    "            model.compile(optimizer='adam', loss= 'mse', metrics= ['mae'])\n",
    "\n",
    "            early_stop = EarlyStopping(patience = 5, restore_best_weights=True)\n",
    "\n",
    "            history=model.fit(train_seq, epochs=100, validation_data=test_seq,\n",
    "                              verbose=1, callbacks = [early_stop])\n",
    "            \n",
    "            output = model.predict(train_seq)\n",
    "            output_lst.append(output[0][0])\n",
    "    row = pd.Series(output_lst)\n",
    "    player_df = player_df.append(row, ignore_index= True)\n",
    "player_df.index = player_lst \n",
    "\n",
    "player_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Stephen Curry</th>\n",
       "      <td>39.417320</td>\n",
       "      <td>36.577568</td>\n",
       "      <td>27.352371</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LeBron James</th>\n",
       "      <td>39.202797</td>\n",
       "      <td>45.097622</td>\n",
       "      <td>28.882462</td>\n",
       "      <td>15.616510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kevin Durant</th>\n",
       "      <td>33.033493</td>\n",
       "      <td>43.634056</td>\n",
       "      <td>39.577541</td>\n",
       "      <td>38.916779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0          1          2          3\n",
       "Stephen Curry  39.417320  36.577568  27.352371        NaN\n",
       "LeBron James   39.202797  45.097622  28.882462  15.616510\n",
       "Kevin Durant   33.033493  43.634056  39.577541  38.916779"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PLAYER_NAME</th>\n",
       "      <th>PLAYER_ID</th>\n",
       "      <th>GAME_ID</th>\n",
       "      <th>SEASON</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG_PCT</th>\n",
       "      <th>FG3M</th>\n",
       "      <th>FG3A</th>\n",
       "      <th>FG3_PCT</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT_PCT</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TNO</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "      <th>PLUS_MINUS</th>\n",
       "      <th>SECONDS</th>\n",
       "      <th>FTSY_PTS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAME_DATE_EST</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-12-17</th>\n",
       "      <td>Stephen Curry</td>\n",
       "      <td>201939</td>\n",
       "      <td>21800449</td>\n",
       "      <td>2018</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.333</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2102</td>\n",
       "      <td>19.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-19</th>\n",
       "      <td>Stephen Curry</td>\n",
       "      <td>201939</td>\n",
       "      <td>21800464</td>\n",
       "      <td>2018</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.571</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.556</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>2220</td>\n",
       "      <td>34.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-22</th>\n",
       "      <td>Stephen Curry</td>\n",
       "      <td>201939</td>\n",
       "      <td>21800484</td>\n",
       "      <td>2018</td>\n",
       "      <td>7.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.318</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.353</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>2369</td>\n",
       "      <td>19.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 PLAYER_NAME  PLAYER_ID   GAME_ID  SEASON   FGM   FGA  FG_PCT  \\\n",
       "GAME_DATE_EST                                                                   \n",
       "2018-12-17     Stephen Curry     201939  21800449    2018   6.0  16.0   0.375   \n",
       "2018-12-19     Stephen Curry     201939  21800464    2018  12.0  21.0   0.571   \n",
       "2018-12-22     Stephen Curry     201939  21800484    2018   7.0  22.0   0.318   \n",
       "\n",
       "               FG3M  FG3A  FG3_PCT  FTM  FTA  FT_PCT  OREB  DREB  REB  AST  \\\n",
       "GAME_DATE_EST                                                                \n",
       "2018-12-17      3.0   9.0    0.333  5.0  5.0   1.000   0.0   7.0  7.0  1.0   \n",
       "2018-12-19      5.0   9.0    0.556  3.0  3.0   1.000   1.0   2.0  3.0  3.0   \n",
       "2018-12-22      6.0  17.0    0.353  2.0  3.0   0.667   2.0   3.0  5.0  5.0   \n",
       "\n",
       "               STL  BLK  TNO   PF   PTS  PLUS_MINUS  SECONDS  FTSY_PTS  \n",
       "GAME_DATE_EST                                                           \n",
       "2018-12-17     2.0  0.0  3.0  3.0  20.0        19.0     2102      19.5  \n",
       "2018-12-19     3.0  1.0  4.0  4.0  32.0        -6.0     2220      34.5  \n",
       "2018-12-22     2.0  0.0  3.0  5.0  22.0        -3.0     2369      19.5  "
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_model():\n",
    "    \n",
    "    start= input(\"What is the first day of the week?\")\n",
    "    end= input(\"What is the last day of the week?\")\n",
    "    date_range= pd.date_range(start= start, end = end)\n",
    "    \n",
    "    player_lst = []\n",
    "    roster_size = int(input(\"How many players are on your roster?\"))\n",
    "    for i in range(roster_size):\n",
    "        player_lst.append(input(\"Type a player's name here.\"))\n",
    "    player_df= pd.DataFrame() \n",
    "    \n",
    "    for player in player_lst:\n",
    "        data_df = df.loc[df['PLAYER_NAME'] == player]\n",
    "        data_df = data_df.iloc[:,4:-1].rolling(window=5).mean()\n",
    "        data_df['FTSY_PTS'] = df.loc[df['PLAYER_NAME']== player]['FTSY_PTS']\n",
    "        data_df.dropna(inplace= True)\n",
    "    \n",
    "        output_lst = []\n",
    "        \n",
    "        for day in date_range:\n",
    "            if day in data_df.index:\n",
    "                X_train = data_df.loc['2015-10-02': day].drop(columns= 'FTSY_PTS')\n",
    "                X_train = X_train[:-1]\n",
    "                y_train = data_df.loc['2015-10-02': day]['FTSY_PTS']\n",
    "                y_train = y_train[:-1]\n",
    "\n",
    "                day_ind = data_df.index.get_loc(day)\n",
    "                X_test = data_df.iloc[[day_ind,day_ind+1]].drop(columns = 'FTSY_PTS')\n",
    "                y_test = data_df.iloc[[day_ind,day_ind+1]]['FTSY_PTS']\n",
    "\n",
    "                ss = StandardScaler()\n",
    "                X_train_sc = ss.fit_transform(X_train)\n",
    "                X_test_sc = ss.transform(X_test)\n",
    "\n",
    "                train_seq = TimeseriesGenerator(X_train_sc, y_train, length=1, batch_size=64)\n",
    "                test_seq = TimeseriesGenerator(X_test_sc, y_test, length = 1, batch_size=64)\n",
    "\n",
    "                model = Sequential()\n",
    "\n",
    "                model.add(LSTM(64, input_shape=(1,20), return_sequences=True))\n",
    "                model.add(LSTM(32, return_sequences=False))\n",
    "\n",
    "                model.add(Dense(32, activation= 'relu'))\n",
    "                model.add(Dropout(.1))\n",
    "\n",
    "                model.add(Dense(8, activation= 'relu'))\n",
    "                model.add(Dropout(.1))\n",
    "\n",
    "                model.add(Dense(2))\n",
    "                model.compile(optimizer='adam', loss= 'mse', metrics= ['mae'])\n",
    "\n",
    "                early_stop = EarlyStopping(patience = 5, restore_best_weights=True)\n",
    "\n",
    "                history=model.fit(train_seq, epochs=100, validation_data=test_seq,\n",
    "                                  verbose=1, callbacks = [early_stop])\n",
    "\n",
    "                output = model.predict(train_seq)\n",
    "                output_lst.append(output[0][0])\n",
    "        row = pd.Series(output_lst)\n",
    "        player_df = player_df.append(row, ignore_index= True)\n",
    "    player_df.index = player_lst \n",
    "    return player_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "What is the first day of the week? 2019-01-08\n",
      "What is the last day of the week? 2019-01-15\n",
      "How many players are on your roster? 6\n",
      "Type a player's name here. Stephen Curry\n",
      "Type a player's name here. LeBron James\n",
      "Type a player's name here. Kevin Durant\n",
      "Type a player's name here. Paul George\n",
      "Type a player's name here. Damian Lillard\n",
      "Type a player's name here. Kyrie Irving\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 5s 508ms/step - loss: 1155.3430 - mae: 32.2387 - val_loss: 1220.9034 - val_mae: 34.9414\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1152.8029 - mae: 32.1997 - val_loss: 1217.9775 - val_mae: 34.8995\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1149.8380 - mae: 32.1545 - val_loss: 1214.5520 - val_mae: 34.8504\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1146.5114 - mae: 32.1009 - val_loss: 1210.4668 - val_mae: 34.7918\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1142.7584 - mae: 32.0422 - val_loss: 1205.6863 - val_mae: 34.7230\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1137.9258 - mae: 31.9685 - val_loss: 1199.8914 - val_mae: 34.6395\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1132.2451 - mae: 31.8766 - val_loss: 1192.3047 - val_mae: 34.5298\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1124.4928 - mae: 31.7572 - val_loss: 1183.1375 - val_mae: 34.3968\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1114.7607 - mae: 31.6012 - val_loss: 1170.7639 - val_mae: 34.2164\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1103.6012 - mae: 31.4183 - val_loss: 1154.9866 - val_mae: 33.9851\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1087.6056 - mae: 31.1617 - val_loss: 1135.0227 - val_mae: 33.6901\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1065.3082 - mae: 30.7976 - val_loss: 1108.2080 - val_mae: 33.2898\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1036.4594 - mae: 30.3314 - val_loss: 1074.5210 - val_mae: 32.7799\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1005.2117 - mae: 29.7712 - val_loss: 1029.2802 - val_mae: 32.0824\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 963.7844 - mae: 29.0550 - val_loss: 971.0878 - val_mae: 31.1621\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 903.5461 - mae: 27.9504 - val_loss: 899.4872 - val_mae: 29.9908\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 846.7573 - mae: 26.9199 - val_loss: 813.8754 - val_mae: 28.5263\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 765.5453 - mae: 25.2418 - val_loss: 716.5724 - val_mae: 26.7628\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 680.3083 - mae: 23.5936 - val_loss: 612.0566 - val_mae: 24.7256\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 604.4453 - mae: 21.7258 - val_loss: 499.0133 - val_mae: 22.3076\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 514.5406 - mae: 19.7471 - val_loss: 386.8726 - val_mae: 19.6068\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 416.5085 - mae: 17.3953 - val_loss: 279.5321 - val_mae: 16.6024\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 363.2895 - mae: 15.9723 - val_loss: 183.8055 - val_mae: 13.3517\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 282.2834 - mae: 13.9247 - val_loss: 108.0464 - val_mae: 10.0706\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 243.3572 - mae: 12.6937 - val_loss: 53.5986 - val_mae: 6.8488\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 209.0380 - mae: 11.8166 - val_loss: 22.8740 - val_mae: 4.1324\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 225.0704 - mae: 12.0508 - val_loss: 6.9796 - val_mae: 1.9668\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 193.3155 - mae: 11.2543 - val_loss: 1.3696 - val_mae: 0.8721\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 176.0996 - mae: 10.6888 - val_loss: 0.1607 - val_mae: 0.3935\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 201.1580 - mae: 11.3802 - val_loss: 0.4755 - val_mae: 0.6355\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 187.7287 - mae: 10.9390 - val_loss: 0.9991 - val_mae: 0.9647\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 173.9116 - mae: 10.7358 - val_loss: 1.4617 - val_mae: 1.2084\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 183.2926 - mae: 10.8167 - val_loss: 2.4143 - val_mae: 1.5387\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 185.4468 - mae: 10.9970 - val_loss: 3.0798 - val_mae: 1.7130\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 4s 163ms/step - loss: 1154.6830 - mae: 32.2348 - val_loss: 2749.5269 - val_mae: 52.4359\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1152.6125 - mae: 32.2026 - val_loss: 2744.7505 - val_mae: 52.3904\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1150.2239 - mae: 32.1658 - val_loss: 2739.0488 - val_mae: 52.3359\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1147.5520 - mae: 32.1258 - val_loss: 2732.1782 - val_mae: 52.2702\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1144.3151 - mae: 32.0744 - val_loss: 2723.4160 - val_mae: 52.1863\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1140.5767 - mae: 32.0159 - val_loss: 2712.0869 - val_mae: 52.0776\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1135.4813 - mae: 31.9391 - val_loss: 2697.3447 - val_mae: 51.9358\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1129.5851 - mae: 31.8506 - val_loss: 2677.1040 - val_mae: 51.7404\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1122.4692 - mae: 31.7321 - val_loss: 2648.7478 - val_mae: 51.4654\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1110.2836 - mae: 31.5374 - val_loss: 2610.9819 - val_mae: 51.0966\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1095.1570 - mae: 31.3045 - val_loss: 2557.8062 - val_mae: 50.5727\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1076.4622 - mae: 31.0051 - val_loss: 2486.2512 - val_mae: 49.8589\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1050.9659 - mae: 30.5972 - val_loss: 2390.3652 - val_mae: 48.8857\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1022.7969 - mae: 30.1170 - val_loss: 2270.1619 - val_mae: 47.6375\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 981.9911 - mae: 29.4316 - val_loss: 2122.6545 - val_mae: 46.0592\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 930.7601 - mae: 28.5395 - val_loss: 1950.3096 - val_mae: 44.1436\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 870.7458 - mae: 27.4476 - val_loss: 1757.4175 - val_mae: 41.8962\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 810.2419 - mae: 26.2901 - val_loss: 1544.4158 - val_mae: 39.2657\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 718.9522 - mae: 24.5276 - val_loss: 1317.8413 - val_mae: 36.2604\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 642.1296 - mae: 22.8201 - val_loss: 1092.3668 - val_mae: 33.0014\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 546.1606 - mae: 20.7960 - val_loss: 868.7656 - val_mae: 29.4173\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 459.8065 - mae: 18.6774 - val_loss: 667.8260 - val_mae: 25.7785\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 379.5353 - mae: 16.5284 - val_loss: 490.6470 - val_mae: 22.0816\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 302.7906 - mae: 14.3480 - val_loss: 348.0379 - val_mae: 18.5846\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 247.7928 - mae: 12.6624 - val_loss: 246.5635 - val_mae: 15.6356\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 212.5592 - mae: 11.6356 - val_loss: 180.1833 - val_mae: 13.3690\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 180.6823 - mae: 10.6763 - val_loss: 145.4960 - val_mae: 12.0236\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 195.7305 - mae: 11.2656 - val_loss: 135.3698 - val_mae: 11.6119\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 181.1803 - mae: 10.9255 - val_loss: 143.9240 - val_mae: 11.9850\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 179.7966 - mae: 10.8036 - val_loss: 168.6603 - val_mae: 12.9822\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 170.0783 - mae: 10.3005 - val_loss: 209.5053 - val_mae: 14.4727\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 172.8566 - mae: 10.4201 - val_loss: 250.9425 - val_mae: 15.8406\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 163.7294 - mae: 10.2280 - val_loss: 281.3210 - val_mae: 16.7724\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 3s 159ms/step - loss: 1155.3179 - mae: 32.2497 - val_loss: 1021.1487 - val_mae: 31.9554\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1153.1976 - mae: 32.2168 - val_loss: 1017.7621 - val_mae: 31.9024\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1151.0339 - mae: 32.1842 - val_loss: 1013.7701 - val_mae: 31.8398\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1148.6965 - mae: 32.1477 - val_loss: 1008.7167 - val_mae: 31.7603\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1145.6687 - mae: 32.1004 - val_loss: 1002.1696 - val_mae: 31.6570\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1141.9097 - mae: 32.0434 - val_loss: 994.2904 - val_mae: 31.5323\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1137.2451 - mae: 31.9713 - val_loss: 983.3601 - val_mae: 31.3584\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1132.2834 - mae: 31.8894 - val_loss: 967.6908 - val_mae: 31.1074\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1123.6160 - mae: 31.7588 - val_loss: 946.0305 - val_mae: 30.7570\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1114.8146 - mae: 31.6204 - val_loss: 917.6980 - val_mae: 30.2924\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1100.6093 - mae: 31.3960 - val_loss: 878.1974 - val_mae: 29.6322\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1082.2755 - mae: 31.1111 - val_loss: 825.9446 - val_mae: 28.7353\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1058.1620 - mae: 30.7069 - val_loss: 757.7129 - val_mae: 27.5195\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1028.7507 - mae: 30.2267 - val_loss: 675.3398 - val_mae: 25.9749\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 983.7412 - mae: 29.4679 - val_loss: 579.3035 - val_mae: 24.0474\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 936.2307 - mae: 28.6447 - val_loss: 476.6906 - val_mae: 21.7979\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 880.7070 - mae: 27.6180 - val_loss: 369.7729 - val_mae: 19.1712\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 806.6707 - mae: 26.2388 - val_loss: 264.4265 - val_mae: 16.1651\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 731.5258 - mae: 24.7855 - val_loss: 170.2101 - val_mae: 12.8863\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 648.7803 - mae: 22.8565 - val_loss: 93.8731 - val_mae: 9.4096\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 551.0315 - mae: 20.7670 - val_loss: 38.2080 - val_mae: 5.6058\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 464.1529 - mae: 18.7093 - val_loss: 11.3445 - val_mae: 2.8922\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 355.1799 - mae: 15.8261 - val_loss: 14.2578 - val_mae: 3.1410\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 324.8850 - mae: 14.7604 - val_loss: 42.6935 - val_mae: 5.6232\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 253.7412 - mae: 12.9322 - val_loss: 85.8342 - val_mae: 8.6086\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 227.1615 - mae: 11.9686 - val_loss: 121.1901 - val_mae: 10.4822\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 219.1338 - mae: 11.7455 - val_loss: 139.5805 - val_mae: 11.3803\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 4s 159ms/step - loss: 1160.6936 - mae: 32.3182 - val_loss: 1557.2008 - val_mae: 39.4614\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1158.7917 - mae: 32.2896 - val_loss: 1554.2178 - val_mae: 39.4236\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1156.8884 - mae: 32.2593 - val_loss: 1550.5764 - val_mae: 39.3774\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1154.4348 - mae: 32.2221 - val_loss: 1546.0417 - val_mae: 39.3197\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1151.7205 - mae: 32.1796 - val_loss: 1540.7664 - val_mae: 39.2526\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1148.1383 - mae: 32.1220 - val_loss: 1533.6968 - val_mae: 39.1624\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1144.4052 - mae: 32.0639 - val_loss: 1524.8182 - val_mae: 39.0489\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1139.1639 - mae: 31.9832 - val_loss: 1513.5151 - val_mae: 38.9039\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1132.2285 - mae: 31.8729 - val_loss: 1499.0667 - val_mae: 38.7177\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1123.7092 - mae: 31.7414 - val_loss: 1478.8599 - val_mae: 38.4559\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1112.7777 - mae: 31.5656 - val_loss: 1454.3257 - val_mae: 38.1355\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1097.8453 - mae: 31.3245 - val_loss: 1421.8213 - val_mae: 37.7068\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1075.9906 - mae: 30.9852 - val_loss: 1382.3545 - val_mae: 37.1797\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1052.3848 - mae: 30.5813 - val_loss: 1334.4688 - val_mae: 36.5300\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1023.6009 - mae: 30.0958 - val_loss: 1272.8135 - val_mae: 35.6761\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 988.4765 - mae: 29.4869 - val_loss: 1204.4736 - val_mae: 34.7051\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 936.8434 - mae: 28.6501 - val_loss: 1116.1561 - val_mae: 33.4084\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 878.7679 - mae: 27.5293 - val_loss: 1015.1127 - val_mae: 31.8603\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 818.0930 - mae: 26.3350 - val_loss: 900.3833 - val_mae: 30.0060\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 740.1233 - mae: 24.8043 - val_loss: 769.7866 - val_mae: 27.7450\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 649.2795 - mae: 22.8975 - val_loss: 637.3336 - val_mae: 25.2431\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 570.5129 - mae: 21.1737 - val_loss: 510.0781 - val_mae: 22.5722\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 476.4479 - mae: 18.8884 - val_loss: 382.2297 - val_mae: 19.5128\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 386.2517 - mae: 16.7103 - val_loss: 268.0635 - val_mae: 16.2831\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 318.3349 - mae: 14.7839 - val_loss: 168.0541 - val_mae: 12.7714\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 255.4178 - mae: 13.0731 - val_loss: 93.3286 - val_mae: 9.2790\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 217.6971 - mae: 12.0462 - val_loss: 43.6769 - val_mae: 5.8959\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 188.3760 - mae: 10.8912 - val_loss: 18.5495 - val_mae: 3.0593\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 199.6758 - mae: 11.2242 - val_loss: 9.5295 - val_mae: 2.7724\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 187.1714 - mae: 11.2013 - val_loss: 6.0572 - val_mae: 2.2660\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 186.5956 - mae: 10.7757 - val_loss: 4.4153 - val_mae: 1.7513\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 182.8642 - mae: 11.0221 - val_loss: 4.4551 - val_mae: 1.6704\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 185.7946 - mae: 10.8737 - val_loss: 6.2225 - val_mae: 2.3097\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 171.6442 - mae: 10.6106 - val_loss: 8.4620 - val_mae: 2.8237\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 184.3969 - mae: 10.7172 - val_loss: 10.2614 - val_mae: 3.1585\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 179.5550 - mae: 10.8272 - val_loss: 10.7805 - val_mae: 3.2507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-308-40c6c3641164>:60: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  row = pd.Series(output_lst)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 3s 160ms/step - loss: 1240.3983 - mae: 33.7990 - val_loss: 1055.9917 - val_mae: 32.4960\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1239.4116 - mae: 33.7843 - val_loss: 1055.3480 - val_mae: 32.4861\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1238.8162 - mae: 33.7754 - val_loss: 1054.7563 - val_mae: 32.4770\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1238.1481 - mae: 33.7658 - val_loss: 1054.1592 - val_mae: 32.4678\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1237.4303 - mae: 33.7552 - val_loss: 1053.4852 - val_mae: 32.4574\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1236.6794 - mae: 33.7438 - val_loss: 1052.7407 - val_mae: 32.4459\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1235.8512 - mae: 33.7314 - val_loss: 1051.9188 - val_mae: 32.4332\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1234.8168 - mae: 33.7160 - val_loss: 1050.9802 - val_mae: 32.4187\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1233.4979 - mae: 33.6969 - val_loss: 1049.9226 - val_mae: 32.4023\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1232.0909 - mae: 33.6757 - val_loss: 1048.7528 - val_mae: 32.3841\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1230.3494 - mae: 33.6496 - val_loss: 1047.3301 - val_mae: 32.3619\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1228.0880 - mae: 33.6152 - val_loss: 1045.6096 - val_mae: 32.3350\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1224.7755 - mae: 33.5659 - val_loss: 1043.5625 - val_mae: 32.3030\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1221.9524 - mae: 33.5201 - val_loss: 1040.9257 - val_mae: 32.2615\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1216.0397 - mae: 33.4328 - val_loss: 1037.4817 - val_mae: 32.2070\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1208.8096 - mae: 33.3126 - val_loss: 1032.9451 - val_mae: 32.1346\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1200.9375 - mae: 33.1823 - val_loss: 1026.8850 - val_mae: 32.0371\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1188.9148 - mae: 32.9931 - val_loss: 1018.5990 - val_mae: 31.9019\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1171.2743 - mae: 32.6734 - val_loss: 1007.4877 - val_mae: 31.7175\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1156.1350 - mae: 32.3897 - val_loss: 993.2258 - val_mae: 31.4751\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1131.1183 - mae: 31.9394 - val_loss: 973.6298 - val_mae: 31.1309\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1111.1058 - mae: 31.5253 - val_loss: 947.7234 - val_mae: 30.6551\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1082.4750 - mae: 30.9484 - val_loss: 918.0260 - val_mae: 30.0806\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1048.1520 - mae: 30.1948 - val_loss: 881.4631 - val_mae: 29.3301\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1011.7466 - mae: 29.3481 - val_loss: 837.6003 - val_mae: 28.3537\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 977.9583 - mae: 28.4751 - val_loss: 789.2903 - val_mae: 27.1691\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 925.9275 - mae: 27.3278 - val_loss: 739.1967 - val_mae: 25.7973\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 899.6695 - mae: 26.4178 - val_loss: 688.9913 - val_mae: 24.2350\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 846.1127 - mae: 25.1492 - val_loss: 642.7064 - val_mae: 22.6212\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 801.4052 - mae: 24.0730 - val_loss: 600.1194 - val_mae: 20.9917\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 757.9560 - mae: 22.9493 - val_loss: 561.0670 - val_mae: 19.4021\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 745.1263 - mae: 22.7499 - val_loss: 525.0578 - val_mae: 17.9620\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 702.8419 - mae: 21.9407 - val_loss: 491.5762 - val_mae: 16.7932\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 673.8530 - mae: 21.6343 - val_loss: 458.2967 - val_mae: 15.7307\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 645.8441 - mae: 21.2221 - val_loss: 425.7625 - val_mae: 14.8934\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 595.3281 - mae: 20.1944 - val_loss: 393.3734 - val_mae: 14.0730\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 563.6147 - mae: 19.6255 - val_loss: 360.9049 - val_mae: 13.6559\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 542.7832 - mae: 19.4201 - val_loss: 328.2494 - val_mae: 13.3506\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 492.4678 - mae: 18.2501 - val_loss: 296.5897 - val_mae: 12.8910\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 448.7957 - mae: 17.5418 - val_loss: 265.0059 - val_mae: 12.4589\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 431.3557 - mae: 17.2371 - val_loss: 233.8981 - val_mae: 11.9469\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 411.5758 - mae: 16.8332 - val_loss: 203.5583 - val_mae: 11.3885\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 363.8150 - mae: 15.8166 - val_loss: 173.9752 - val_mae: 10.7002\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 343.3881 - mae: 15.2663 - val_loss: 145.7039 - val_mae: 9.9011\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 299.7198 - mae: 14.1955 - val_loss: 119.3596 - val_mae: 8.9923\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 299.2584 - mae: 14.1031 - val_loss: 95.3337 - val_mae: 8.1557\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 282.5480 - mae: 13.6445 - val_loss: 73.7579 - val_mae: 7.3785\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 231.2004 - mae: 11.9767 - val_loss: 55.2514 - val_mae: 6.5352\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 228.2100 - mae: 12.0425 - val_loss: 39.7060 - val_mae: 5.5579\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 200.7240 - mae: 11.1837 - val_loss: 27.4135 - val_mae: 4.7014\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 207.2062 - mae: 11.2184 - val_loss: 18.2541 - val_mae: 3.9431\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 203.9661 - mae: 11.2147 - val_loss: 11.7742 - val_mae: 3.2864\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 169.6380 - mae: 10.1836 - val_loss: 7.2433 - val_mae: 2.6498\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 183.2522 - mae: 10.3531 - val_loss: 4.0596 - val_mae: 2.0054\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 176.3610 - mae: 10.2394 - val_loss: 2.2280 - val_mae: 1.4918\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 160.7836 - mae: 9.6489 - val_loss: 1.6846 - val_mae: 1.1963\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 168.8072 - mae: 9.8587 - val_loss: 1.7980 - val_mae: 0.9750\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 167.1503 - mae: 9.7239 - val_loss: 1.2389 - val_mae: 0.9111\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 156.1765 - mae: 9.6640 - val_loss: 1.2671 - val_mae: 1.0299\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 165.5325 - mae: 9.9633 - val_loss: 1.6732 - val_mae: 1.2310\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 168.7658 - mae: 9.7768 - val_loss: 2.1965 - val_mae: 1.4301\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 155.8871 - mae: 9.5336 - val_loss: 2.1753 - val_mae: 1.4328\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 158.3512 - mae: 9.6844 - val_loss: 3.3020 - val_mae: 1.7557\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 3s 156ms/step - loss: 1238.4216 - mae: 33.7732 - val_loss: 1188.8051 - val_mae: 34.4790\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1237.1195 - mae: 33.7539 - val_loss: 1187.0541 - val_mae: 34.4536\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1235.5345 - mae: 33.7312 - val_loss: 1184.9485 - val_mae: 34.4230\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1233.6479 - mae: 33.7038 - val_loss: 1182.3616 - val_mae: 34.3854\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1231.6202 - mae: 33.6736 - val_loss: 1179.1809 - val_mae: 34.3390\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1228.8151 - mae: 33.6325 - val_loss: 1174.9478 - val_mae: 34.2772\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1225.7249 - mae: 33.5878 - val_loss: 1169.4377 - val_mae: 34.1965\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1221.6028 - mae: 33.5280 - val_loss: 1161.6914 - val_mae: 34.0826\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1216.7976 - mae: 33.4563 - val_loss: 1150.8231 - val_mae: 33.9221\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1209.3693 - mae: 33.3464 - val_loss: 1135.2039 - val_mae: 33.6900\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1198.8861 - mae: 33.1929 - val_loss: 1112.3816 - val_mae: 33.3474\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1186.5570 - mae: 33.0071 - val_loss: 1081.2798 - val_mae: 32.8741\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1168.0962 - mae: 32.7352 - val_loss: 1037.5936 - val_mae: 32.1964\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1149.0588 - mae: 32.4421 - val_loss: 983.1920 - val_mae: 31.3303\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1115.2094 - mae: 31.8973 - val_loss: 913.0349 - val_mae: 30.1738\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1077.6558 - mae: 31.2809 - val_loss: 829.0767 - val_mae: 28.7247\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1033.7736 - mae: 30.5584 - val_loss: 733.6422 - val_mae: 26.9775\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 985.4617 - mae: 29.6765 - val_loss: 633.6757 - val_mae: 25.0100\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 931.1536 - mae: 28.6996 - val_loss: 530.4391 - val_mae: 22.7919\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 859.0056 - mae: 27.2260 - val_loss: 428.6759 - val_mae: 20.3598\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 789.6214 - mae: 25.7840 - val_loss: 331.4523 - val_mae: 17.7139\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 733.8884 - mae: 24.5241 - val_loss: 242.6017 - val_mae: 14.8626\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 650.9961 - mae: 22.6052 - val_loss: 167.7243 - val_mae: 11.7423\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 566.8244 - mae: 20.7540 - val_loss: 109.5819 - val_mae: 8.4862\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 502.8352 - mae: 19.3228 - val_loss: 71.3413 - val_mae: 6.6355\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 419.5935 - mae: 17.0120 - val_loss: 51.4568 - val_mae: 6.8234\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 373.0201 - mae: 16.0833 - val_loss: 44.1565 - val_mae: 6.6340\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 321.5016 - mae: 14.7152 - val_loss: 42.0330 - val_mae: 6.0437\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 275.3939 - mae: 13.3542 - val_loss: 38.0279 - val_mae: 5.0594\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 250.8288 - mae: 12.7690 - val_loss: 33.1899 - val_mae: 4.2160\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 232.4931 - mae: 12.1225 - val_loss: 28.0602 - val_mae: 4.5065\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 201.7183 - mae: 11.2617 - val_loss: 23.1353 - val_mae: 4.4773\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 198.9218 - mae: 11.1950 - val_loss: 18.2798 - val_mae: 4.1833\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 183.1009 - mae: 10.8526 - val_loss: 14.9712 - val_mae: 3.8635\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 171.4406 - mae: 10.3206 - val_loss: 11.2699 - val_mae: 3.3497\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 160.0100 - mae: 9.9443 - val_loss: 7.2500 - val_mae: 2.6489\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 143.5512 - mae: 9.6194 - val_loss: 4.4744 - val_mae: 2.0227\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 166.4659 - mae: 10.3767 - val_loss: 3.0952 - val_mae: 1.6386\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 150.1809 - mae: 9.4772 - val_loss: 2.0145 - val_mae: 1.2765\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 167.1029 - mae: 10.1634 - val_loss: 1.5215 - val_mae: 1.0869\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 163.6869 - mae: 9.9221 - val_loss: 1.2892 - val_mae: 1.0151\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 157.4403 - mae: 9.6264 - val_loss: 1.2609 - val_mae: 1.0369\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 149.9098 - mae: 9.7966 - val_loss: 1.3509 - val_mae: 1.1105\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 155.1201 - mae: 10.0660 - val_loss: 1.0551 - val_mae: 0.9799\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 163.4918 - mae: 10.0777 - val_loss: 1.2042 - val_mae: 1.0455\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 151.9631 - mae: 9.5389 - val_loss: 1.0965 - val_mae: 0.9814\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 145.0973 - mae: 9.3878 - val_loss: 0.7890 - val_mae: 0.8213\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 169.6602 - mae: 10.1324 - val_loss: 0.6901 - val_mae: 0.7709\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 143.2719 - mae: 9.5148 - val_loss: 0.8623 - val_mae: 0.8878\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 144.9844 - mae: 9.4236 - val_loss: 0.9729 - val_mae: 0.9521\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 136.7212 - mae: 9.1819 - val_loss: 0.7680 - val_mae: 0.8252\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 141.4277 - mae: 9.3608 - val_loss: 0.7170 - val_mae: 0.7860\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 150.0390 - mae: 9.5272 - val_loss: 0.4321 - val_mae: 0.5838\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 149.1508 - mae: 9.6875 - val_loss: 0.3720 - val_mae: 0.5470\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 155.6983 - mae: 10.0374 - val_loss: 0.3100 - val_mae: 0.4658\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 129.1498 - mae: 8.9643 - val_loss: 0.2245 - val_mae: 0.3497\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 144.8011 - mae: 9.6887 - val_loss: 0.1566 - val_mae: 0.3765\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 141.1753 - mae: 9.4508 - val_loss: 0.2434 - val_mae: 0.3806\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 146.6635 - mae: 9.7222 - val_loss: 0.5420 - val_mae: 0.6304\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 140.1010 - mae: 9.3194 - val_loss: 0.4620 - val_mae: 0.5541\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 151.9501 - mae: 9.7510 - val_loss: 0.2312 - val_mae: 0.3824\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 141.2666 - mae: 9.0190 - val_loss: 0.1866 - val_mae: 0.3714\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 4s 171ms/step - loss: 1236.6816 - mae: 33.7521 - val_loss: 1517.6140 - val_mae: 38.9566\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1234.0029 - mae: 33.7122 - val_loss: 1514.5090 - val_mae: 38.9167\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1230.7808 - mae: 33.6656 - val_loss: 1511.1057 - val_mae: 38.8729\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1227.2422 - mae: 33.6126 - val_loss: 1507.2439 - val_mae: 38.8232\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1223.0176 - mae: 33.5489 - val_loss: 1502.7209 - val_mae: 38.7649\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1217.6832 - mae: 33.4708 - val_loss: 1497.1362 - val_mae: 38.6928\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1211.8472 - mae: 33.3844 - val_loss: 1490.3667 - val_mae: 38.6052\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1204.7034 - mae: 33.2789 - val_loss: 1481.8458 - val_mae: 38.4946\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1196.0106 - mae: 33.1453 - val_loss: 1471.2026 - val_mae: 38.3561\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1183.2618 - mae: 32.9548 - val_loss: 1457.4968 - val_mae: 38.1769\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1169.1611 - mae: 32.7393 - val_loss: 1439.8591 - val_mae: 37.9450\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1150.5165 - mae: 32.4487 - val_loss: 1416.9241 - val_mae: 37.6413\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1120.0017 - mae: 31.9786 - val_loss: 1387.6538 - val_mae: 37.2500\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1090.4321 - mae: 31.5022 - val_loss: 1349.6917 - val_mae: 36.7362\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1056.2172 - mae: 30.9606 - val_loss: 1302.3984 - val_mae: 36.0857\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1007.3817 - mae: 30.1431 - val_loss: 1242.5273 - val_mae: 35.2447\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 955.1172 - mae: 29.1761 - val_loss: 1167.1643 - val_mae: 34.1561\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 884.3346 - mae: 27.9664 - val_loss: 1078.4192 - val_mae: 32.8271\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 801.8143 - mae: 26.4590 - val_loss: 980.6758 - val_mae: 31.2972\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 726.3062 - mae: 24.9610 - val_loss: 868.6753 - val_mae: 29.4449\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 637.4316 - mae: 22.9119 - val_loss: 750.1602 - val_mae: 27.3467\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 526.9710 - mae: 20.4908 - val_loss: 614.7063 - val_mae: 24.7267\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 437.4101 - mae: 18.0937 - val_loss: 479.4653 - val_mae: 21.7928\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 348.6653 - mae: 15.6992 - val_loss: 346.9682 - val_mae: 18.4650\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 270.1930 - mae: 13.5130 - val_loss: 231.6634 - val_mae: 14.9687\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 214.8311 - mae: 12.0099 - val_loss: 142.0439 - val_mae: 11.5290\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 201.1440 - mae: 11.3906 - val_loss: 86.6030 - val_mae: 8.7471\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 181.3001 - mae: 10.9838 - val_loss: 57.6339 - val_mae: 6.8855\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 175.0784 - mae: 10.3894 - val_loss: 43.0873 - val_mae: 5.7806\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 155.8824 - mae: 10.1188 - val_loss: 38.2698 - val_mae: 5.4446\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 153.5447 - mae: 10.1498 - val_loss: 37.9803 - val_mae: 5.5246\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 153.1624 - mae: 9.9564 - val_loss: 42.0697 - val_mae: 5.9811\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 142.9020 - mae: 9.4215 - val_loss: 45.8954 - val_mae: 6.3684\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 136.5920 - mae: 9.3954 - val_loss: 46.9165 - val_mae: 6.5030\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 142.3345 - mae: 9.4999 - val_loss: 48.0116 - val_mae: 6.6329\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 150.0480 - mae: 9.5347 - val_loss: 47.9480 - val_mae: 6.6660\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 3s 164ms/step - loss: 1237.7645 - mae: 33.7730 - val_loss: 1598.9641 - val_mae: 39.9870\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1236.2668 - mae: 33.7509 - val_loss: 1597.7410 - val_mae: 39.9717\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1234.5566 - mae: 33.7259 - val_loss: 1596.0596 - val_mae: 39.9507\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1232.6237 - mae: 33.6980 - val_loss: 1593.8049 - val_mae: 39.9225\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1230.1672 - mae: 33.6617 - val_loss: 1591.1785 - val_mae: 39.8896\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1227.3177 - mae: 33.6208 - val_loss: 1587.9624 - val_mae: 39.8492\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1223.6831 - mae: 33.5673 - val_loss: 1583.8827 - val_mae: 39.7980\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1218.8798 - mae: 33.4955 - val_loss: 1579.1724 - val_mae: 39.7387\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1212.7101 - mae: 33.4045 - val_loss: 1572.9460 - val_mae: 39.6603\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1205.2450 - mae: 33.2959 - val_loss: 1564.2908 - val_mae: 39.5509\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1193.9810 - mae: 33.1295 - val_loss: 1553.2229 - val_mae: 39.4106\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1180.9153 - mae: 32.9330 - val_loss: 1539.3081 - val_mae: 39.2335\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1161.8528 - mae: 32.6393 - val_loss: 1518.5977 - val_mae: 38.9682\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1136.5336 - mae: 32.2577 - val_loss: 1488.8942 - val_mae: 38.5843\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1104.2612 - mae: 31.7633 - val_loss: 1445.5037 - val_mae: 38.0159\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1059.6646 - mae: 31.0045 - val_loss: 1388.5691 - val_mae: 37.2561\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1001.0347 - mae: 30.0541 - val_loss: 1309.3638 - val_mae: 36.1707\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 932.9615 - mae: 28.8965 - val_loss: 1204.1417 - val_mae: 34.6725\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 855.0377 - mae: 27.4012 - val_loss: 1068.9901 - val_mae: 32.6402\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 764.5032 - mae: 25.6497 - val_loss: 911.1558 - val_mae: 30.0816\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 660.0978 - mae: 23.5862 - val_loss: 734.2836 - val_mae: 26.9063\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 563.8282 - mae: 21.4516 - val_loss: 552.0909 - val_mae: 23.1514\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 461.2126 - mae: 18.8794 - val_loss: 383.7659 - val_mae: 18.9863\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 375.7128 - mae: 16.6035 - val_loss: 248.1055 - val_mae: 14.7431\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 297.6655 - mae: 14.3504 - val_loss: 149.1509 - val_mae: 10.5881\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 251.0009 - mae: 13.1956 - val_loss: 88.1259 - val_mae: 6.9528\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 213.3503 - mae: 11.7878 - val_loss: 55.5271 - val_mae: 6.0898\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 210.4757 - mae: 11.4532 - val_loss: 37.5913 - val_mae: 5.5156\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 195.5816 - mae: 11.0940 - val_loss: 26.2210 - val_mae: 4.6388\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 168.0343 - mae: 10.5149 - val_loss: 18.3698 - val_mae: 3.7556\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 180.6980 - mae: 10.6483 - val_loss: 13.7554 - val_mae: 2.9193\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 173.9220 - mae: 10.3057 - val_loss: 12.2368 - val_mae: 2.7565\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 170.0595 - mae: 10.0360 - val_loss: 11.4050 - val_mae: 2.9930\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 162.9713 - mae: 10.1946 - val_loss: 10.7362 - val_mae: 3.0832\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 161.4885 - mae: 10.0188 - val_loss: 9.7147 - val_mae: 3.0190\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 154.4963 - mae: 9.8507 - val_loss: 9.4848 - val_mae: 3.0354\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 148.2309 - mae: 9.6704 - val_loss: 8.1930 - val_mae: 2.8400\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 162.6987 - mae: 9.8460 - val_loss: 7.4275 - val_mae: 2.7154\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 172.0183 - mae: 10.0231 - val_loss: 6.4379 - val_mae: 2.5303\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 153.0214 - mae: 9.6929 - val_loss: 5.5354 - val_mae: 2.3457\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 167.8758 - mae: 10.3486 - val_loss: 4.4977 - val_mae: 2.1120\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 135.5203 - mae: 9.2494 - val_loss: 4.0392 - val_mae: 1.9959\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 139.8415 - mae: 9.3327 - val_loss: 4.0000 - val_mae: 1.9804\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 153.2850 - mae: 9.6715 - val_loss: 4.0303 - val_mae: 1.9833\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 149.5826 - mae: 9.5766 - val_loss: 4.3862 - val_mae: 2.0723\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 162.9481 - mae: 10.0150 - val_loss: 4.6831 - val_mae: 2.1408\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 150.6848 - mae: 9.7529 - val_loss: 4.6219 - val_mae: 2.1237\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 148.3846 - mae: 9.8206 - val_loss: 4.9421 - val_mae: 2.2008\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 3s 157ms/step - loss: 800.3148 - mae: 26.2932 - val_loss: 752.9233 - val_mae: 27.4394\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 797.9521 - mae: 26.2480 - val_loss: 750.0319 - val_mae: 27.3867\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 795.2430 - mae: 26.1994 - val_loss: 746.8521 - val_mae: 27.3286\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 792.2382 - mae: 26.1420 - val_loss: 742.7546 - val_mae: 27.2535\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 788.7772 - mae: 26.0749 - val_loss: 737.9249 - val_mae: 27.1648\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 784.6017 - mae: 25.9998 - val_loss: 732.2504 - val_mae: 27.0601\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 778.8487 - mae: 25.8979 - val_loss: 724.7823 - val_mae: 26.9218\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 772.5775 - mae: 25.7799 - val_loss: 714.5217 - val_mae: 26.7305\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 763.6238 - mae: 25.6203 - val_loss: 701.3688 - val_mae: 26.4833\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 755.5651 - mae: 25.4533 - val_loss: 683.0645 - val_mae: 26.1353\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 737.6252 - mae: 25.1295 - val_loss: 658.5319 - val_mae: 25.6613\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 718.7094 - mae: 24.7751 - val_loss: 626.6426 - val_mae: 25.0317\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 694.3982 - mae: 24.2953 - val_loss: 583.5255 - val_mae: 24.1538\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 666.8760 - mae: 23.7641 - val_loss: 527.3884 - val_mae: 22.9598\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 633.1665 - mae: 23.0744 - val_loss: 457.2224 - val_mae: 21.3718\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 592.8589 - mae: 22.2314 - val_loss: 380.6746 - val_mae: 19.4893\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 542.6974 - mae: 21.1103 - val_loss: 296.9797 - val_mae: 17.1932\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 483.9264 - mae: 19.7440 - val_loss: 212.6578 - val_mae: 14.5106\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 437.3896 - mae: 18.4627 - val_loss: 139.6463 - val_mae: 11.6922\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 381.1047 - mae: 16.9607 - val_loss: 78.9498 - val_mae: 8.6724\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 332.9359 - mae: 15.4835 - val_loss: 36.2350 - val_mae: 5.6518\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 279.3829 - mae: 14.0221 - val_loss: 12.4200 - val_mae: 2.8328\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 241.0366 - mae: 12.7992 - val_loss: 4.1192 - val_mae: 1.9813\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 214.4980 - mae: 11.4433 - val_loss: 3.8558 - val_mae: 1.6515\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 170.2948 - mae: 10.3049 - val_loss: 5.7714 - val_mae: 2.0377\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 182.9649 - mae: 10.7919 - val_loss: 5.0470 - val_mae: 2.0864\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 161.4301 - mae: 10.0955 - val_loss: 2.7430 - val_mae: 1.6023\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 154.4575 - mae: 9.7865 - val_loss: 0.7916 - val_mae: 0.8840\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 153.1096 - mae: 9.7065 - val_loss: 0.0403 - val_mae: 0.1694\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 141.5010 - mae: 9.1999 - val_loss: 0.2980 - val_mae: 0.4854\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 140.6965 - mae: 9.3783 - val_loss: 0.8553 - val_mae: 0.8593\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 154.2881 - mae: 9.6169 - val_loss: 1.2298 - val_mae: 1.0462\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 141.0636 - mae: 9.3821 - val_loss: 1.6640 - val_mae: 1.2402\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 153.5538 - mae: 9.7372 - val_loss: 2.0641 - val_mae: 1.4041\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 3s 156ms/step - loss: 799.3129 - mae: 26.2745 - val_loss: 624.1304 - val_mae: 24.9826\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 798.1028 - mae: 26.2521 - val_loss: 623.0919 - val_mae: 24.9618\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 796.7183 - mae: 26.2259 - val_loss: 621.5095 - val_mae: 24.9301\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 795.1092 - mae: 26.1964 - val_loss: 619.5792 - val_mae: 24.8913\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 792.9993 - mae: 26.1572 - val_loss: 617.2048 - val_mae: 24.8435\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 790.4682 - mae: 26.1085 - val_loss: 613.9139 - val_mae: 24.7771\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 787.6595 - mae: 26.0596 - val_loss: 609.6321 - val_mae: 24.6904\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 783.8558 - mae: 25.9906 - val_loss: 603.7025 - val_mae: 24.5697\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 779.2068 - mae: 25.9017 - val_loss: 594.9244 - val_mae: 24.3898\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 772.7330 - mae: 25.7824 - val_loss: 582.3734 - val_mae: 24.1297\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 763.7874 - mae: 25.6180 - val_loss: 564.5388 - val_mae: 23.7545\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 753.4341 - mae: 25.4283 - val_loss: 540.0969 - val_mae: 23.2286\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 736.6039 - mae: 25.1069 - val_loss: 507.7221 - val_mae: 22.5101\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 722.8097 - mae: 24.8562 - val_loss: 463.7545 - val_mae: 21.4891\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 699.3387 - mae: 24.3777 - val_loss: 411.3369 - val_mae: 20.1927\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 672.7727 - mae: 23.8506 - val_loss: 355.2826 - val_mae: 18.6895\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 641.6570 - mae: 23.2275 - val_loss: 293.4552 - val_mae: 16.8471\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 611.1888 - mae: 22.5642 - val_loss: 233.4259 - val_mae: 14.7959\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 568.6620 - mae: 21.5380 - val_loss: 178.9751 - val_mae: 12.5850\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 545.4905 - mae: 20.9855 - val_loss: 132.4391 - val_mae: 10.2209\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 498.1851 - mae: 19.8674 - val_loss: 96.7129 - val_mae: 7.7761\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 460.6124 - mae: 18.9053 - val_loss: 73.0919 - val_mae: 6.7151\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 423.2874 - mae: 17.8973 - val_loss: 61.9063 - val_mae: 7.3412\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 390.2285 - mae: 17.0003 - val_loss: 61.4914 - val_mae: 7.8181\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 358.8868 - mae: 16.1969 - val_loss: 68.1073 - val_mae: 8.1378\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 320.9695 - mae: 15.0550 - val_loss: 77.6411 - val_mae: 8.2847\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 285.9873 - mae: 14.1869 - val_loss: 86.0724 - val_mae: 8.2313\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 265.7364 - mae: 13.3876 - val_loss: 92.0165 - val_mae: 8.0373\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 228.9320 - mae: 12.1944 - val_loss: 94.3552 - val_mae: 7.7192\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 3s 159ms/step - loss: 798.6668 - mae: 26.2684 - val_loss: 990.5634 - val_mae: 31.4732\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 796.8462 - mae: 26.2332 - val_loss: 988.6390 - val_mae: 31.4426\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 794.7900 - mae: 26.1940 - val_loss: 986.5839 - val_mae: 31.4099\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 792.4050 - mae: 26.1468 - val_loss: 983.9073 - val_mae: 31.3673\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 789.7021 - mae: 26.0976 - val_loss: 980.8673 - val_mae: 31.3188\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 786.0760 - mae: 26.0290 - val_loss: 977.2362 - val_mae: 31.2608\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 782.4545 - mae: 25.9584 - val_loss: 972.6324 - val_mae: 31.1870\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 777.3763 - mae: 25.8630 - val_loss: 966.6429 - val_mae: 31.0909\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 770.8620 - mae: 25.7333 - val_loss: 958.7056 - val_mae: 30.9629\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 762.6649 - mae: 25.5753 - val_loss: 948.8422 - val_mae: 30.8032\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 750.8829 - mae: 25.3553 - val_loss: 935.9288 - val_mae: 30.5928\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 736.9680 - mae: 25.0731 - val_loss: 919.1879 - val_mae: 30.3178\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 719.5972 - mae: 24.7107 - val_loss: 895.9780 - val_mae: 29.9324\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 694.4844 - mae: 24.2253 - val_loss: 864.2490 - val_mae: 29.3972\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 667.1404 - mae: 23.6496 - val_loss: 824.3004 - val_mae: 28.7089\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 618.6326 - mae: 22.6786 - val_loss: 772.0120 - val_mae: 27.7819\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 581.1024 - mae: 21.7618 - val_loss: 710.5458 - val_mae: 26.6502\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 520.2201 - mae: 20.3655 - val_loss: 635.8861 - val_mae: 25.2064\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 453.0377 - mae: 18.6038 - val_loss: 543.4374 - val_mae: 23.2926\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 382.4175 - mae: 16.7010 - val_loss: 440.1454 - val_mae: 20.9443\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 314.0907 - mae: 14.7642 - val_loss: 332.6595 - val_mae: 18.1744\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 247.3686 - mae: 12.6876 - val_loss: 232.8884 - val_mae: 15.1465\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 207.9642 - mae: 11.4743 - val_loss: 148.8924 - val_mae: 12.0057\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 171.0649 - mae: 10.3908 - val_loss: 86.4452 - val_mae: 8.9727\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 165.9301 - mae: 10.0875 - val_loss: 49.6539 - val_mae: 6.5649\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 173.7359 - mae: 10.2620 - val_loss: 33.7627 - val_mae: 5.2439\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 157.8468 - mae: 9.9321 - val_loss: 28.8266 - val_mae: 4.8407\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 160.1741 - mae: 10.0992 - val_loss: 29.5821 - val_mae: 5.0237\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 157.8318 - mae: 10.0081 - val_loss: 32.7884 - val_mae: 5.4235\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 147.0109 - mae: 9.4264 - val_loss: 37.2371 - val_mae: 5.8857\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 139.6810 - mae: 9.3387 - val_loss: 38.2288 - val_mae: 6.0148\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 153.0287 - mae: 9.7140 - val_loss: 36.8564 - val_mae: 5.9306\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 4s 357ms/step - loss: 797.8744 - mae: 26.2607 - val_loss: 1366.8120 - val_mae: 36.9704\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 795.5046 - mae: 26.2151 - val_loss: 1364.5424 - val_mae: 36.9397\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 792.7971 - mae: 26.1634 - val_loss: 1361.7842 - val_mae: 36.9024\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 789.6556 - mae: 26.1051 - val_loss: 1358.6782 - val_mae: 36.8603\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 785.9722 - mae: 26.0341 - val_loss: 1355.0596 - val_mae: 36.8111\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 781.6852 - mae: 25.9533 - val_loss: 1350.9646 - val_mae: 36.7555\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 775.6338 - mae: 25.8388 - val_loss: 1345.7557 - val_mae: 36.6845\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 768.5598 - mae: 25.6935 - val_loss: 1339.0708 - val_mae: 36.5933\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 759.3935 - mae: 25.5191 - val_loss: 1331.5177 - val_mae: 36.4900\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 748.5715 - mae: 25.3072 - val_loss: 1321.2965 - val_mae: 36.3496\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 733.4182 - mae: 24.9895 - val_loss: 1309.0887 - val_mae: 36.1813\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 715.2973 - mae: 24.6294 - val_loss: 1293.1440 - val_mae: 35.9603\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 688.3372 - mae: 24.0769 - val_loss: 1273.1479 - val_mae: 35.6811\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 660.8904 - mae: 23.5008 - val_loss: 1245.9250 - val_mae: 35.2976\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 627.3411 - mae: 22.7705 - val_loss: 1213.9983 - val_mae: 34.8424\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 580.7316 - mae: 21.6810 - val_loss: 1170.5079 - val_mae: 34.2126\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 528.0165 - mae: 20.4597 - val_loss: 1117.0518 - val_mae: 33.4223\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 476.6224 - mae: 19.1173 - val_loss: 1052.6986 - val_mae: 32.4453\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 420.8713 - mae: 17.7324 - val_loss: 977.6331 - val_mae: 31.2671\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 361.8227 - mae: 16.0759 - val_loss: 890.6952 - val_mae: 29.8445\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 303.8964 - mae: 14.3883 - val_loss: 790.2959 - val_mae: 28.1120\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 252.3734 - mae: 12.9201 - val_loss: 679.4621 - val_mae: 26.0657\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 204.1132 - mae: 11.4303 - val_loss: 563.7186 - val_mae: 23.7409\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 181.4708 - mae: 10.4370 - val_loss: 447.0403 - val_mae: 21.1396\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 160.0876 - mae: 9.9610 - val_loss: 346.1964 - val_mae: 18.6006\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 150.4426 - mae: 9.7066 - val_loss: 272.9157 - val_mae: 16.5141\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 145.4950 - mae: 9.4136 - val_loss: 224.4095 - val_mae: 14.9760\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 143.0971 - mae: 9.4548 - val_loss: 197.8153 - val_mae: 14.0626\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 143.1501 - mae: 9.3706 - val_loss: 188.6244 - val_mae: 13.7334\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 135.2733 - mae: 9.3488 - val_loss: 184.5851 - val_mae: 13.5861\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 135.2423 - mae: 9.2131 - val_loss: 178.6734 - val_mae: 13.3669\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 141.0650 - mae: 9.3643 - val_loss: 179.7927 - val_mae: 13.4086\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 135.9514 - mae: 9.0680 - val_loss: 178.0101 - val_mae: 13.3419\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 127.1241 - mae: 8.8075 - val_loss: 177.2942 - val_mae: 13.3151\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 129.6840 - mae: 8.7345 - val_loss: 174.4752 - val_mae: 13.2089\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 141.7594 - mae: 9.3186 - val_loss: 173.2843 - val_mae: 13.1637\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 135.7464 - mae: 9.0067 - val_loss: 171.0011 - val_mae: 13.0767\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 121.2557 - mae: 8.7554 - val_loss: 168.9004 - val_mae: 12.9962\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 130.7375 - mae: 8.8992 - val_loss: 163.5775 - val_mae: 12.7897\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 133.6777 - mae: 9.0995 - val_loss: 157.5399 - val_mae: 12.5514\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 121.6971 - mae: 8.7289 - val_loss: 153.8468 - val_mae: 12.4034\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 124.7226 - mae: 8.8519 - val_loss: 150.1360 - val_mae: 12.2529\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 118.9650 - mae: 8.5470 - val_loss: 143.0587 - val_mae: 11.9607\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 124.2793 - mae: 8.6981 - val_loss: 143.5721 - val_mae: 11.9821\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 113.6921 - mae: 8.3018 - val_loss: 146.3203 - val_mae: 12.0961\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 120.3325 - mae: 8.7012 - val_loss: 145.6049 - val_mae: 12.0663\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 117.0075 - mae: 8.3713 - val_loss: 145.2441 - val_mae: 12.0511\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 113.5568 - mae: 8.3959 - val_loss: 144.6472 - val_mae: 12.0261\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 3s 157ms/step - loss: 868.1139 - mae: 27.5910 - val_loss: 1257.9448 - val_mae: 35.4675\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 866.1611 - mae: 27.5567 - val_loss: 1254.8904 - val_mae: 35.4244\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 864.1579 - mae: 27.5203 - val_loss: 1251.4062 - val_mae: 35.3752\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 861.8608 - mae: 27.4793 - val_loss: 1247.8745 - val_mae: 35.3252\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 859.2952 - mae: 27.4312 - val_loss: 1243.5762 - val_mae: 35.2643\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 855.7331 - mae: 27.3710 - val_loss: 1238.5415 - val_mae: 35.1929\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 852.5056 - mae: 27.3081 - val_loss: 1232.7257 - val_mae: 35.1101\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 846.2713 - mae: 27.2017 - val_loss: 1224.9337 - val_mae: 34.9989\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 839.5425 - mae: 27.0787 - val_loss: 1214.6333 - val_mae: 34.8513\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 831.2614 - mae: 26.9246 - val_loss: 1201.4377 - val_mae: 34.6613\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 818.5623 - mae: 26.6848 - val_loss: 1182.2794 - val_mae: 34.3835\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 801.8928 - mae: 26.3727 - val_loss: 1156.5634 - val_mae: 34.0069\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 780.1216 - mae: 25.9521 - val_loss: 1122.1262 - val_mae: 33.4957\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 756.7296 - mae: 25.5035 - val_loss: 1073.9833 - val_mae: 32.7672\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 717.2495 - mae: 24.7046 - val_loss: 1016.8339 - val_mae: 31.8799\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 672.6940 - mae: 23.7731 - val_loss: 942.2397 - val_mae: 30.6820\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 615.9257 - mae: 22.5854 - val_loss: 849.4407 - val_mae: 29.1198\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 549.4010 - mae: 21.0424 - val_loss: 740.0337 - val_mae: 27.1578\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 481.5818 - mae: 19.3430 - val_loss: 615.6587 - val_mae: 24.7303\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 409.5373 - mae: 17.3580 - val_loss: 483.0833 - val_mae: 21.8333\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 335.6241 - mae: 15.4099 - val_loss: 356.9144 - val_mae: 18.6415\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 278.1700 - mae: 13.4418 - val_loss: 245.9002 - val_mae: 15.2642\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 212.2507 - mae: 11.5203 - val_loss: 162.5232 - val_mae: 12.1060\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 201.1374 - mae: 11.0477 - val_loss: 107.4092 - val_mae: 9.4795\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 188.7889 - mae: 11.0031 - val_loss: 75.4758 - val_mae: 7.6452\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 198.2265 - mae: 11.0502 - val_loss: 60.5004 - val_mae: 6.7778\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 173.1988 - mae: 10.3370 - val_loss: 59.8490 - val_mae: 6.9863\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 180.8070 - mae: 10.7179 - val_loss: 66.3049 - val_mae: 7.6403\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 176.1101 - mae: 10.3818 - val_loss: 72.2552 - val_mae: 8.1557\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 158.7516 - mae: 9.8777 - val_loss: 75.2567 - val_mae: 8.4271\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 157.6700 - mae: 9.7671 - val_loss: 77.0557 - val_mae: 8.5967\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 154.7588 - mae: 9.6212 - val_loss: 75.5416 - val_mae: 8.5522\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 3s 154ms/step - loss: 867.4308 - mae: 27.5843 - val_loss: 649.4982 - val_mae: 25.4853\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 865.9694 - mae: 27.5583 - val_loss: 647.4880 - val_mae: 25.4458\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 864.1594 - mae: 27.5247 - val_loss: 645.3336 - val_mae: 25.4034\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 862.2476 - mae: 27.4919 - val_loss: 642.9309 - val_mae: 25.3561\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 859.8505 - mae: 27.4484 - val_loss: 639.9145 - val_mae: 25.2965\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 856.8755 - mae: 27.3944 - val_loss: 636.2079 - val_mae: 25.2231\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 853.2369 - mae: 27.3325 - val_loss: 631.6339 - val_mae: 25.1323\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 849.1462 - mae: 27.2531 - val_loss: 625.4069 - val_mae: 25.0081\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 842.6235 - mae: 27.1319 - val_loss: 616.9309 - val_mae: 24.8380\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 835.6938 - mae: 27.0052 - val_loss: 604.7224 - val_mae: 24.5910\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 826.3458 - mae: 26.8292 - val_loss: 588.2505 - val_mae: 24.2537\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 813.3890 - mae: 26.5931 - val_loss: 564.2612 - val_mae: 23.7539\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 792.9630 - mae: 26.2131 - val_loss: 531.7084 - val_mae: 23.0584\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 773.0487 - mae: 25.8048 - val_loss: 488.7102 - val_mae: 22.1064\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 736.4215 - mae: 25.1130 - val_loss: 435.5549 - val_mae: 20.8697\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 695.7501 - mae: 24.2867 - val_loss: 370.9365 - val_mae: 19.2597\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 650.6986 - mae: 23.3246 - val_loss: 297.2755 - val_mae: 17.2415\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 589.8054 - mae: 21.9378 - val_loss: 220.3354 - val_mae: 14.8408\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 512.3786 - mae: 20.0760 - val_loss: 146.4500 - val_mae: 12.0872\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 448.8084 - mae: 18.5491 - val_loss: 80.3026 - val_mae: 8.9081\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 377.6447 - mae: 16.5041 - val_loss: 31.9237 - val_mae: 5.4663\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 311.8622 - mae: 14.3758 - val_loss: 7.2392 - val_mae: 1.9146\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 243.8092 - mae: 12.5171 - val_loss: 7.7925 - val_mae: 2.3349\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 211.7150 - mae: 11.3687 - val_loss: 27.2399 - val_mae: 4.5571\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 186.3807 - mae: 10.6431 - val_loss: 51.1163 - val_mae: 6.7290\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 189.7742 - mae: 10.5764 - val_loss: 59.1743 - val_mae: 7.4451\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 185.2088 - mae: 10.6246 - val_loss: 52.7937 - val_mae: 7.1474\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 4s 417ms/step - loss: 869.0817 - mae: 27.6166 - val_loss: 649.7541 - val_mae: 25.4903\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 868.3330 - mae: 27.6034 - val_loss: 649.1788 - val_mae: 25.4790\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 867.5984 - mae: 27.5903 - val_loss: 648.5370 - val_mae: 25.4664\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 866.6913 - mae: 27.5740 - val_loss: 647.7681 - val_mae: 25.4513\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 865.5802 - mae: 27.5544 - val_loss: 646.8203 - val_mae: 25.4327\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 864.3021 - mae: 27.5323 - val_loss: 645.7343 - val_mae: 25.4113\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 862.8137 - mae: 27.5047 - val_loss: 644.4454 - val_mae: 25.3859\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 860.8272 - mae: 27.4693 - val_loss: 642.7635 - val_mae: 25.3528\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 858.3060 - mae: 27.4246 - val_loss: 640.6006 - val_mae: 25.3100\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 854.8810 - mae: 27.3630 - val_loss: 637.7075 - val_mae: 25.2528\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 850.5680 - mae: 27.2852 - val_loss: 633.7882 - val_mae: 25.1751\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 844.6495 - mae: 27.1767 - val_loss: 627.9886 - val_mae: 25.0596\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 835.4693 - mae: 27.0154 - val_loss: 619.6208 - val_mae: 24.8920\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 823.0383 - mae: 26.7766 - val_loss: 607.5880 - val_mae: 24.6490\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 810.1486 - mae: 26.5411 - val_loss: 590.3243 - val_mae: 24.2962\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 785.8354 - mae: 26.0649 - val_loss: 565.5674 - val_mae: 23.7811\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 759.4263 - mae: 25.5612 - val_loss: 531.2612 - val_mae: 23.0483\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 718.6723 - mae: 24.7656 - val_loss: 484.9845 - val_mae: 22.0213\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 663.3954 - mae: 23.6383 - val_loss: 426.5283 - val_mae: 20.6511\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 610.5091 - mae: 22.5119 - val_loss: 355.7180 - val_mae: 18.8586\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 538.2910 - mae: 20.8095 - val_loss: 276.5635 - val_mae: 16.6281\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 454.6974 - mae: 18.7676 - val_loss: 195.1953 - val_mae: 13.9690\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 386.4440 - mae: 16.8528 - val_loss: 118.9160 - val_mae: 10.9027\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 304.1490 - mae: 14.4978 - val_loss: 57.1273 - val_mae: 7.5566\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 259.1486 - mae: 13.0088 - val_loss: 16.3202 - val_mae: 4.0389\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 214.4466 - mae: 11.3209 - val_loss: 0.6087 - val_mae: 0.7801\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 183.1679 - mae: 10.4954 - val_loss: 3.8769 - val_mae: 1.9665\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 197.4395 - mae: 10.7048 - val_loss: 15.1948 - val_mae: 3.8933\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 170.5186 - mae: 10.0626 - val_loss: 24.9735 - val_mae: 4.9917\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 173.7307 - mae: 10.2687 - val_loss: 25.6472 - val_mae: 5.0568\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 167.9582 - mae: 10.3713 - val_loss: 20.9571 - val_mae: 4.5674\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 3s 162ms/step - loss: 868.2791 - mae: 27.6084 - val_loss: 1295.2925 - val_mae: 35.9902\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 867.5717 - mae: 27.5956 - val_loss: 1294.4944 - val_mae: 35.9791\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 866.7273 - mae: 27.5808 - val_loss: 1293.5996 - val_mae: 35.9666\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 865.8621 - mae: 27.5655 - val_loss: 1292.5786 - val_mae: 35.9524\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 864.8544 - mae: 27.5473 - val_loss: 1291.3765 - val_mae: 35.9357\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 863.6689 - mae: 27.5262 - val_loss: 1289.9215 - val_mae: 35.9155\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 862.2048 - mae: 27.4999 - val_loss: 1288.1882 - val_mae: 35.8913\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 860.5286 - mae: 27.4694 - val_loss: 1286.1311 - val_mae: 35.8627\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 858.0792 - mae: 27.4265 - val_loss: 1283.4568 - val_mae: 35.8254\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 855.0311 - mae: 27.3716 - val_loss: 1280.3140 - val_mae: 35.7815\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 850.5355 - mae: 27.2880 - val_loss: 1276.1536 - val_mae: 35.7233\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 844.9485 - mae: 27.1883 - val_loss: 1270.4316 - val_mae: 35.6431\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 837.3645 - mae: 27.0504 - val_loss: 1262.9175 - val_mae: 35.5376\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 825.1459 - mae: 26.8240 - val_loss: 1252.4814 - val_mae: 35.3904\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 808.6606 - mae: 26.5148 - val_loss: 1237.3586 - val_mae: 35.1761\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 788.5725 - mae: 26.1217 - val_loss: 1217.1346 - val_mae: 34.8875\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 761.4030 - mae: 25.6001 - val_loss: 1188.9807 - val_mae: 34.4816\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 717.3741 - mae: 24.7474 - val_loss: 1150.4652 - val_mae: 33.9185\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 677.5297 - mae: 23.8848 - val_loss: 1100.1318 - val_mae: 33.1682\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 616.2967 - mae: 22.5674 - val_loss: 1030.8398 - val_mae: 32.1067\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 557.5234 - mae: 21.1328 - val_loss: 950.8265 - val_mae: 30.8355\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 476.7358 - mae: 19.1155 - val_loss: 852.5283 - val_mae: 29.1981\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 439.8009 - mae: 17.8652 - val_loss: 741.0333 - val_mae: 27.2219\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 341.0157 - mae: 15.3680 - val_loss: 617.3256 - val_mae: 24.8459\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 278.1995 - mae: 13.4696 - val_loss: 497.4260 - val_mae: 22.3029\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 242.6387 - mae: 12.1457 - val_loss: 389.2910 - val_mae: 19.7301\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 218.4922 - mae: 11.1640 - val_loss: 307.0494 - val_mae: 17.5220\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 199.7404 - mae: 11.0235 - val_loss: 248.5857 - val_mae: 15.7650\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 186.0756 - mae: 10.5861 - val_loss: 208.8498 - val_mae: 14.4488\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 197.3717 - mae: 10.8201 - val_loss: 192.7735 - val_mae: 13.8794\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 189.8218 - mae: 10.7697 - val_loss: 193.1722 - val_mae: 13.8922\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 186.9847 - mae: 10.4015 - val_loss: 196.6708 - val_mae: 14.0169\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 178.4849 - mae: 10.5115 - val_loss: 208.8915 - val_mae: 14.4454\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 179.7677 - mae: 10.2559 - val_loss: 217.4730 - val_mae: 14.7394\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 183.8060 - mae: 10.2747 - val_loss: 224.6859 - val_mae: 14.9829\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 3s 166ms/step - loss: 778.2494 - mae: 25.8152 - val_loss: 701.5887 - val_mae: 26.4875\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 777.1804 - mae: 25.7955 - val_loss: 700.5143 - val_mae: 26.4672\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 775.9680 - mae: 25.7717 - val_loss: 699.2300 - val_mae: 26.4430\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 774.3312 - mae: 25.7403 - val_loss: 697.7444 - val_mae: 26.4149\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 772.7598 - mae: 25.7119 - val_loss: 696.2009 - val_mae: 26.3856\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 770.9155 - mae: 25.6767 - val_loss: 694.3438 - val_mae: 26.3504\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 768.7781 - mae: 25.6347 - val_loss: 692.2324 - val_mae: 26.3103\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 766.4962 - mae: 25.5945 - val_loss: 689.7983 - val_mae: 26.2640\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 763.7511 - mae: 25.5381 - val_loss: 686.9818 - val_mae: 26.2103\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 759.3392 - mae: 25.4552 - val_loss: 683.8179 - val_mae: 26.1499\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 755.1207 - mae: 25.3754 - val_loss: 680.0890 - val_mae: 26.0785\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 749.0852 - mae: 25.2532 - val_loss: 675.9414 - val_mae: 25.9989\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 740.8881 - mae: 25.1056 - val_loss: 670.7156 - val_mae: 25.8982\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 731.3225 - mae: 24.9160 - val_loss: 664.8924 - val_mae: 25.7855\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 717.9837 - mae: 24.6663 - val_loss: 657.3955 - val_mae: 25.6397\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 695.5519 - mae: 24.2213 - val_loss: 648.7758 - val_mae: 25.4710\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 681.5397 - mae: 23.9118 - val_loss: 637.6433 - val_mae: 25.2516\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 652.1052 - mae: 23.2994 - val_loss: 624.9797 - val_mae: 24.9995\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 614.9230 - mae: 22.4727 - val_loss: 608.3503 - val_mae: 24.6647\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 581.6528 - mae: 21.7288 - val_loss: 587.7686 - val_mae: 24.2438\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 533.7558 - mae: 20.6027 - val_loss: 562.0880 - val_mae: 23.7083\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 485.7949 - mae: 19.3408 - val_loss: 529.7229 - val_mae: 23.0155\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 445.1517 - mae: 18.2824 - val_loss: 490.6865 - val_mae: 22.1511\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 390.2828 - mae: 16.8010 - val_loss: 443.1633 - val_mae: 21.0510\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 332.1893 - mae: 15.1502 - val_loss: 387.2944 - val_mae: 19.6791\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 292.5322 - mae: 13.9388 - val_loss: 329.3894 - val_mae: 18.1481\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 260.9537 - mae: 13.0992 - val_loss: 269.4678 - val_mae: 16.4141\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 237.4785 - mae: 12.6095 - val_loss: 212.5021 - val_mae: 14.5757\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 219.6515 - mae: 12.1206 - val_loss: 164.6555 - val_mae: 12.8296\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 214.3248 - mae: 11.8620 - val_loss: 125.9208 - val_mae: 11.2190\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 187.6878 - mae: 11.0528 - val_loss: 97.7523 - val_mae: 9.8846\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 170.9717 - mae: 10.5130 - val_loss: 79.8127 - val_mae: 8.9316\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 182.9013 - mae: 11.0324 - val_loss: 62.7709 - val_mae: 7.9208\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 164.2241 - mae: 10.2124 - val_loss: 49.9734 - val_mae: 7.0673\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 166.8864 - mae: 10.2036 - val_loss: 41.4279 - val_mae: 6.4350\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 148.9613 - mae: 9.7544 - val_loss: 33.4861 - val_mae: 5.7857\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 150.0309 - mae: 9.7874 - val_loss: 28.6622 - val_mae: 5.3531\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 152.7246 - mae: 9.8266 - val_loss: 25.0650 - val_mae: 5.0063\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 159.4995 - mae: 10.0818 - val_loss: 23.0291 - val_mae: 4.7989\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 149.7650 - mae: 9.7554 - val_loss: 19.9424 - val_mae: 4.4655\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 156.1233 - mae: 9.9706 - val_loss: 15.3573 - val_mae: 3.9184\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 146.8975 - mae: 9.6325 - val_loss: 12.9141 - val_mae: 3.5928\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 135.1555 - mae: 9.3763 - val_loss: 12.2510 - val_mae: 3.4988\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 153.0332 - mae: 9.5892 - val_loss: 12.6724 - val_mae: 3.5581\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 145.2431 - mae: 9.7905 - val_loss: 12.2653 - val_mae: 3.5000\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 141.9337 - mae: 9.3819 - val_loss: 12.8249 - val_mae: 3.5789\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 135.9999 - mae: 9.0334 - val_loss: 13.8125 - val_mae: 3.7139\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 136.5005 - mae: 9.3019 - val_loss: 15.2472 - val_mae: 3.9020\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 5s 428ms/step - loss: 775.8402 - mae: 25.7637 - val_loss: 1087.8657 - val_mae: 32.9828\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 774.6124 - mae: 25.7398 - val_loss: 1086.4296 - val_mae: 32.9610\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 773.3017 - mae: 25.7150 - val_loss: 1084.8459 - val_mae: 32.9370\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 772.1079 - mae: 25.6910 - val_loss: 1083.1028 - val_mae: 32.9105\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 770.5359 - mae: 25.6622 - val_loss: 1081.0696 - val_mae: 32.8796\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 768.4482 - mae: 25.6234 - val_loss: 1078.7375 - val_mae: 32.8441\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 766.5350 - mae: 25.5849 - val_loss: 1075.8958 - val_mae: 32.8008\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 763.8892 - mae: 25.5351 - val_loss: 1072.5812 - val_mae: 32.7503\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 760.4517 - mae: 25.4683 - val_loss: 1068.2859 - val_mae: 32.6846\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 755.7765 - mae: 25.3825 - val_loss: 1063.0131 - val_mae: 32.6039\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 749.5340 - mae: 25.2560 - val_loss: 1056.4541 - val_mae: 32.5031\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 742.9476 - mae: 25.1315 - val_loss: 1047.5718 - val_mae: 32.3662\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 730.4660 - mae: 24.8941 - val_loss: 1035.9868 - val_mae: 32.1867\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 722.4673 - mae: 24.7306 - val_loss: 1020.4870 - val_mae: 31.9450\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 703.1910 - mae: 24.3611 - val_loss: 999.6649 - val_mae: 31.6174\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 676.4090 - mae: 23.8205 - val_loss: 972.2896 - val_mae: 31.1814\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 659.6702 - mae: 23.4145 - val_loss: 937.2452 - val_mae: 30.6140\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 614.2689 - mae: 22.4492 - val_loss: 890.0342 - val_mae: 29.8322\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 570.0685 - mae: 21.4625 - val_loss: 829.5750 - val_mae: 28.7993\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 521.6880 - mae: 20.2204 - val_loss: 758.5491 - val_mae: 27.5351\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 475.4153 - mae: 19.0846 - val_loss: 668.6666 - val_mae: 25.8445\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 416.5298 - mae: 17.5293 - val_loss: 569.8978 - val_mae: 23.8453\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 366.0512 - mae: 16.0424 - val_loss: 460.3701 - val_mae: 21.4077\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 329.5945 - mae: 15.0185 - val_loss: 357.5237 - val_mae: 18.8347\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 272.4711 - mae: 13.4623 - val_loss: 274.7306 - val_mae: 16.4936\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 245.8974 - mae: 12.6138 - val_loss: 205.5028 - val_mae: 14.2623\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 237.0782 - mae: 12.4743 - val_loss: 156.6647 - val_mae: 12.4727\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 214.0584 - mae: 11.8779 - val_loss: 122.7405 - val_mae: 11.0631\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 203.3398 - mae: 11.4034 - val_loss: 102.8692 - val_mae: 10.1411\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 193.6794 - mae: 11.3119 - val_loss: 98.7665 - val_mae: 9.9370\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 192.5477 - mae: 11.3301 - val_loss: 95.6012 - val_mae: 9.7720\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 171.5383 - mae: 10.5896 - val_loss: 91.3805 - val_mae: 9.5522\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 178.4187 - mae: 10.7266 - val_loss: 86.7604 - val_mae: 9.3107\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 173.8503 - mae: 10.5953 - val_loss: 84.8479 - val_mae: 9.2107\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 162.1781 - mae: 10.1646 - val_loss: 80.4554 - val_mae: 8.9696\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 158.3624 - mae: 9.7906 - val_loss: 74.8409 - val_mae: 8.6490\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 159.1637 - mae: 10.0035 - val_loss: 66.9805 - val_mae: 8.1776\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 152.1882 - mae: 9.8711 - val_loss: 68.6036 - val_mae: 8.2722\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 153.0133 - mae: 9.7837 - val_loss: 73.2032 - val_mae: 8.5458\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 160.1659 - mae: 10.1532 - val_loss: 76.7665 - val_mae: 8.7545\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 158.7526 - mae: 10.0820 - val_loss: 84.1886 - val_mae: 9.1699\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 148.8689 - mae: 9.8139 - val_loss: 89.1048 - val_mae: 9.4352\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 4s 179ms/step - loss: 775.2972 - mae: 25.7612 - val_loss: 2302.0173 - val_mae: 47.9793\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 773.7072 - mae: 25.7311 - val_loss: 2299.5857 - val_mae: 47.9540\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 772.3581 - mae: 25.7049 - val_loss: 2296.8730 - val_mae: 47.9257\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 770.3159 - mae: 25.6666 - val_loss: 2293.8645 - val_mae: 47.8943\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 768.3288 - mae: 25.6292 - val_loss: 2290.4146 - val_mae: 47.8583\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 766.3563 - mae: 25.5912 - val_loss: 2286.4414 - val_mae: 47.8167\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 763.6606 - mae: 25.5389 - val_loss: 2281.8433 - val_mae: 47.7686\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 759.3116 - mae: 25.4574 - val_loss: 2276.1553 - val_mae: 47.7090\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 754.8323 - mae: 25.3723 - val_loss: 2269.3389 - val_mae: 47.6375\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 749.4088 - mae: 25.2741 - val_loss: 2261.9006 - val_mae: 47.5594\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 741.8327 - mae: 25.1256 - val_loss: 2252.5757 - val_mae: 47.4612\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 732.1540 - mae: 24.9281 - val_loss: 2238.8879 - val_mae: 47.3168\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 720.5292 - mae: 24.7095 - val_loss: 2223.6807 - val_mae: 47.1557\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 705.4311 - mae: 24.4241 - val_loss: 2202.5093 - val_mae: 46.9306\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 685.1288 - mae: 23.9996 - val_loss: 2173.4009 - val_mae: 46.6193\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 649.6127 - mae: 23.2468 - val_loss: 2132.0493 - val_mae: 46.1734\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 611.9793 - mae: 22.4532 - val_loss: 2076.8389 - val_mae: 45.5712\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 586.5716 - mae: 21.8087 - val_loss: 2006.1184 - val_mae: 44.7878\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 531.1678 - mae: 20.5496 - val_loss: 1912.2410 - val_mae: 43.7261\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 475.6050 - mae: 19.1421 - val_loss: 1790.2502 - val_mae: 42.3063\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 417.5743 - mae: 17.6537 - val_loss: 1640.6448 - val_mae: 40.4966\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 375.8841 - mae: 16.3331 - val_loss: 1464.9424 - val_mae: 38.2577\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 329.5385 - mae: 15.1335 - val_loss: 1272.8838 - val_mae: 35.6453\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 287.3286 - mae: 13.8709 - val_loss: 1084.1918 - val_mae: 32.8756\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 244.9121 - mae: 12.7199 - val_loss: 914.1179 - val_mae: 30.1706\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 224.7559 - mae: 12.1548 - val_loss: 776.7211 - val_mae: 27.8056\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 200.1389 - mae: 11.5143 - val_loss: 677.5002 - val_mae: 25.9768\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 198.2036 - mae: 11.2989 - val_loss: 609.4186 - val_mae: 24.6406\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 177.0795 - mae: 10.7518 - val_loss: 577.9255 - val_mae: 24.0006\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 184.4936 - mae: 10.7765 - val_loss: 572.7264 - val_mae: 23.8998\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 168.0325 - mae: 10.3152 - val_loss: 580.0375 - val_mae: 24.0590\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 168.6094 - mae: 10.6068 - val_loss: 566.1562 - val_mae: 23.7734\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 169.7102 - mae: 10.3267 - val_loss: 548.5101 - val_mae: 23.4029\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 150.3707 - mae: 9.6345 - val_loss: 537.5333 - val_mae: 23.1703\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 139.3661 - mae: 9.4759 - val_loss: 535.5891 - val_mae: 23.1311\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 149.7032 - mae: 9.5517 - val_loss: 533.4019 - val_mae: 23.0860\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 150.2115 - mae: 9.6135 - val_loss: 528.0223 - val_mae: 22.9711\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 143.1466 - mae: 9.7385 - val_loss: 525.9496 - val_mae: 22.9275\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 147.9831 - mae: 9.4496 - val_loss: 531.1018 - val_mae: 23.0409\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 136.7887 - mae: 9.2235 - val_loss: 538.9174 - val_mae: 23.2110\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 144.1196 - mae: 9.5238 - val_loss: 537.2770 - val_mae: 23.1764\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 142.1018 - mae: 9.5276 - val_loss: 553.0109 - val_mae: 23.5140\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 152.0611 - mae: 9.9442 - val_loss: 559.4906 - val_mae: 23.6519\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Stephen Curry</th>\n",
       "      <td>39.054016</td>\n",
       "      <td>39.576366</td>\n",
       "      <td>18.900721</td>\n",
       "      <td>37.958733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LeBron James</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kevin Durant</th>\n",
       "      <td>34.871994</td>\n",
       "      <td>37.119099</td>\n",
       "      <td>36.331291</td>\n",
       "      <td>40.028496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Paul George</th>\n",
       "      <td>30.296940</td>\n",
       "      <td>4.182769</td>\n",
       "      <td>35.215824</td>\n",
       "      <td>29.181782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Damian Lillard</th>\n",
       "      <td>15.226656</td>\n",
       "      <td>7.204335</td>\n",
       "      <td>14.481609</td>\n",
       "      <td>18.914305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kyrie Irving</th>\n",
       "      <td>26.670706</td>\n",
       "      <td>29.359381</td>\n",
       "      <td>28.990250</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0          1          2          3\n",
       "Stephen Curry   39.054016  39.576366  18.900721  37.958733\n",
       "LeBron James          NaN        NaN        NaN        NaN\n",
       "Kevin Durant    34.871994  37.119099  36.331291  40.028496\n",
       "Paul George     30.296940   4.182769  35.215824  29.181782\n",
       "Damian Lillard  15.226656   7.204335  14.481609  18.914305\n",
       "Kyrie Irving    26.670706  29.359381  28.990250        NaN"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking actual vs model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curry=df.loc[df['PLAYER_NAME'] == 'Stephen Curry']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curry.loc['2018-12-15' : '2018-12-22']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
